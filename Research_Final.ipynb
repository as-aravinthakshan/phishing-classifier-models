{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DFscmWH7vBt"
      },
      "source": [
        "## Grad Boost IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwl9Rh7DsEbE",
        "outputId": "2d674a41-fef1-46f3-d400-9ca02c9213b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train - Accuracy: 0.9528, Precision: 0.9498, Recall: 0.9659, F1: 0.9578\n",
            "Test - Accuracy: 0.9507, Precision: 0.9491, Recall: 0.9649, F1: 0.9569\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gradient Boosting model\n",
        "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(model, X, y):\n",
        "    predictions = model.predict(X)\n",
        "    accuracy = accuracy_score(y, predictions)\n",
        "    precision = precision_score(y, predictions)\n",
        "    recall = recall_score(y, predictions)\n",
        "    f1 = f1_score(y, predictions)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate on training data\n",
        "train_accuracy, train_precision, train_recall, train_f1 = evaluate(model, X_train, y_train)\n",
        "print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w22kzTLl72MN"
      },
      "source": [
        "## SVM( LINEAR  ) IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-Mymme1smOR",
        "outputId": "cf308bbe-b74a-4339-d21b-3e7f1fb9d8cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train - Accuracy: 0.9284, Precision: 0.9263, Recall: 0.9461, F1: 0.9361\n",
            "Test - Accuracy: 0.9285, Precision: 0.9262, Recall: 0.9498, F1: 0.9378\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the SVM model\n",
        "model = SVC(kernel='linear', C=1, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(model, X, y):\n",
        "    predictions = model.predict(X)\n",
        "    accuracy = accuracy_score(y, predictions)\n",
        "    precision = precision_score(y, predictions)\n",
        "    recall = recall_score(y, predictions)\n",
        "    f1 = f1_score(y, predictions)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate on training data\n",
        "train_accuracy, train_precision, train_recall, train_f1 = evaluate(model, X_train, y_train)\n",
        "print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16z53om38FlW"
      },
      "source": [
        "## CNN IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXzXLa7DtnbD",
        "outputId": "1d7ff802-3e64-44ee-f5f5-70dea9d7036b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 010, Loss: 0.6136\n",
            "Train - Accuracy: 0.7353, Precision: 0.6795, Recall: 0.9890, F1: 0.8055\n",
            "Epoch: 020, Loss: 0.4629\n",
            "Train - Accuracy: 0.8414, Precision: 0.8318, Recall: 0.8947, F1: 0.8621\n",
            "Epoch: 030, Loss: 0.3162\n",
            "Train - Accuracy: 0.8779, Precision: 0.8862, Recall: 0.8945, F1: 0.8904\n",
            "Epoch: 040, Loss: 0.2525\n",
            "Train - Accuracy: 0.8956, Precision: 0.9049, Recall: 0.9070, F1: 0.9060\n",
            "Epoch: 050, Loss: 0.2166\n",
            "Train - Accuracy: 0.9101, Precision: 0.9134, Recall: 0.9255, F1: 0.9194\n",
            "Epoch: 060, Loss: 0.1950\n",
            "Train - Accuracy: 0.9227, Precision: 0.9216, Recall: 0.9404, F1: 0.9309\n",
            "Epoch: 070, Loss: 0.1819\n",
            "Train - Accuracy: 0.9289, Precision: 0.9264, Recall: 0.9470, F1: 0.9365\n",
            "Epoch: 080, Loss: 0.1720\n",
            "Train - Accuracy: 0.9326, Precision: 0.9318, Recall: 0.9478, F1: 0.9397\n",
            "Epoch: 090, Loss: 0.1640\n",
            "Train - Accuracy: 0.9348, Precision: 0.9333, Recall: 0.9502, F1: 0.9417\n",
            "Epoch: 100, Loss: 0.1572\n",
            "Train - Accuracy: 0.9366, Precision: 0.9351, Recall: 0.9517, F1: 0.9433\n",
            "Epoch: 110, Loss: 0.1509\n",
            "Train - Accuracy: 0.9405, Precision: 0.9374, Recall: 0.9565, F1: 0.9469\n",
            "Epoch: 120, Loss: 0.1451\n",
            "Train - Accuracy: 0.9430, Precision: 0.9393, Recall: 0.9592, F1: 0.9491\n",
            "Epoch: 130, Loss: 0.1397\n",
            "Train - Accuracy: 0.9449, Precision: 0.9414, Recall: 0.9604, F1: 0.9508\n",
            "Epoch: 140, Loss: 0.1344\n",
            "Train - Accuracy: 0.9467, Precision: 0.9432, Recall: 0.9619, F1: 0.9524\n",
            "Epoch: 150, Loss: 0.1297\n",
            "Train - Accuracy: 0.9454, Precision: 0.9369, Recall: 0.9665, F1: 0.9515\n",
            "Epoch: 160, Loss: 0.1253\n",
            "Train - Accuracy: 0.9478, Precision: 0.9433, Recall: 0.9637, F1: 0.9534\n",
            "Epoch: 170, Loss: 0.1212\n",
            "Train - Accuracy: 0.9492, Precision: 0.9484, Recall: 0.9606, F1: 0.9545\n",
            "Epoch: 180, Loss: 0.1177\n",
            "Train - Accuracy: 0.9522, Precision: 0.9520, Recall: 0.9623, F1: 0.9571\n",
            "Epoch: 190, Loss: 0.1146\n",
            "Train - Accuracy: 0.9510, Precision: 0.9488, Recall: 0.9637, F1: 0.9562\n",
            "Epoch: 200, Loss: 0.1116\n",
            "Train - Accuracy: 0.9530, Precision: 0.9517, Recall: 0.9641, F1: 0.9578\n",
            "Test - Accuracy: 0.9426, Precision: 0.9386, Recall: 0.9618, F1: 0.9500\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Add a channel dimension\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)  # Add a channel dimension\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(32 * (X_train.shape[2] // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define the loss function and the optimizer\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "def train_model():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = accuracy_score(labels.cpu(), predicted.cpu())\n",
        "        precision = precision_score(labels.cpu(), predicted.cpu())\n",
        "        recall = recall_score(labels.cpu(), predicted.cpu())\n",
        "        f1 = f1_score(labels.cpu(), predicted.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 201):\n",
        "    loss = train_model()\n",
        "    if epoch % 10 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqGLQmtH8MYx"
      },
      "source": [
        "## CNN Leaky Relu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR1RWfgnuZ5H",
        "outputId": "4b6be60d-75b1-4e49-cc72-52816e3c8f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 010, Loss: 0.6390\n",
            "Train - Accuracy: 0.6203, Precision: 0.5936, Recall: 0.9986, F1: 0.7446\n",
            "Epoch: 020, Loss: 0.5150\n",
            "Train - Accuracy: 0.8217, Precision: 0.7955, Recall: 0.9131, F1: 0.8502\n",
            "Epoch: 030, Loss: 0.3543\n",
            "Train - Accuracy: 0.8786, Precision: 0.8741, Recall: 0.9123, F1: 0.8928\n",
            "Epoch: 040, Loss: 0.2661\n",
            "Train - Accuracy: 0.8950, Precision: 0.8974, Recall: 0.9151, F1: 0.9062\n",
            "Epoch: 050, Loss: 0.2270\n",
            "Train - Accuracy: 0.9101, Precision: 0.9138, Recall: 0.9251, F1: 0.9194\n",
            "Epoch: 060, Loss: 0.2013\n",
            "Train - Accuracy: 0.9198, Precision: 0.9159, Recall: 0.9419, F1: 0.9287\n",
            "Epoch: 070, Loss: 0.1849\n",
            "Train - Accuracy: 0.9267, Precision: 0.9225, Recall: 0.9474, F1: 0.9348\n",
            "Epoch: 080, Loss: 0.1741\n",
            "Train - Accuracy: 0.9288, Precision: 0.9265, Recall: 0.9466, F1: 0.9364\n",
            "Epoch: 090, Loss: 0.1650\n",
            "Train - Accuracy: 0.9310, Precision: 0.9289, Recall: 0.9482, F1: 0.9384\n",
            "Epoch: 100, Loss: 0.1567\n",
            "Train - Accuracy: 0.9336, Precision: 0.9319, Recall: 0.9496, F1: 0.9407\n",
            "Epoch: 110, Loss: 0.1494\n",
            "Train - Accuracy: 0.9366, Precision: 0.9340, Recall: 0.9529, F1: 0.9434\n",
            "Epoch: 120, Loss: 0.1430\n",
            "Train - Accuracy: 0.9387, Precision: 0.9360, Recall: 0.9547, F1: 0.9453\n",
            "Epoch: 130, Loss: 0.1373\n",
            "Train - Accuracy: 0.9411, Precision: 0.9392, Recall: 0.9555, F1: 0.9473\n",
            "Epoch: 140, Loss: 0.1321\n",
            "Train - Accuracy: 0.9445, Precision: 0.9465, Recall: 0.9537, F1: 0.9501\n",
            "Epoch: 150, Loss: 0.1276\n",
            "Train - Accuracy: 0.9464, Precision: 0.9469, Recall: 0.9570, F1: 0.9519\n",
            "Epoch: 160, Loss: 0.1234\n",
            "Train - Accuracy: 0.9475, Precision: 0.9456, Recall: 0.9606, F1: 0.9530\n",
            "Epoch: 170, Loss: 0.1197\n",
            "Train - Accuracy: 0.9491, Precision: 0.9482, Recall: 0.9606, F1: 0.9544\n",
            "Epoch: 180, Loss: 0.1162\n",
            "Train - Accuracy: 0.9518, Precision: 0.9480, Recall: 0.9661, F1: 0.9570\n",
            "Epoch: 190, Loss: 0.1129\n",
            "Train - Accuracy: 0.9536, Precision: 0.9543, Recall: 0.9625, F1: 0.9584\n",
            "Epoch: 200, Loss: 0.1100\n",
            "Train - Accuracy: 0.9543, Precision: 0.9525, Recall: 0.9657, F1: 0.9591\n",
            "Test - Accuracy: 0.9435, Precision: 0.9414, Recall: 0.9602, F1: 0.9507\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Add a channel dimension\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)  # Add a channel dimension\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the CNN model with LeakyReLU\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "        self.fc1 = nn.Linear(32 * (X_train.shape[2] // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.leaky_relu(self.conv1(x)))\n",
        "        x = self.pool(self.leaky_relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define the loss function and the optimizer\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "def train_model():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = accuracy_score(labels.cpu(), predicted.cpu())\n",
        "        precision = precision_score(labels.cpu(), predicted.cpu())\n",
        "        recall = recall_score(labels.cpu(), predicted.cpu())\n",
        "        f1 = f1_score(labels.cpu(), predicted.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 201):\n",
        "    loss = train_model()\n",
        "    if epoch % 10 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_G4a3v78QGR"
      },
      "source": [
        "## KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQC0hqNU3FZg",
        "outputId": "a3ca0b50-a849-492a-f229-0c5f4c7c96f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN Train - Accuracy: 0.9665, Precision: 0.9658, Recall: 0.9741, F1: 0.9699\n",
            "KNN Test - Accuracy: 0.9408, Precision: 0.9411, Recall: 0.9554, F1: 0.9482\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Initialize and train the KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train.numpy(), y_train.numpy())\n",
        "\n",
        "# Make predictions on the train set\n",
        "y_train_pred = knn.predict(X_train.numpy())\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_test_pred = knn.predict(X_test.numpy())\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_accuracy = accuracy_score(y_train.numpy(), y_train_pred)\n",
        "train_precision = precision_score(y_train.numpy(), y_train_pred)\n",
        "train_recall = recall_score(y_train.numpy(), y_train_pred)\n",
        "train_f1 = f1_score(y_train.numpy(), y_train_pred)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = accuracy_score(y_test.numpy(), y_test_pred)\n",
        "test_precision = precision_score(y_test.numpy(), y_test_pred)\n",
        "test_recall = recall_score(y_test.numpy(), y_test_pred)\n",
        "test_f1 = f1_score(y_test.numpy(), y_test_pred)\n",
        "\n",
        "print(f'KNN Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "print(f'KNN Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5181qdv8To8"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yChGNkPT3qZ7",
        "outputId": "af3a2d86-a91b-4d2d-87ed-41013fece162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 010, Loss: 0.8541\n",
            "Train - Accuracy: 0.3405, Precision: 0.4075, Recall: 0.4186, F1: 0.4130\n",
            "Epoch: 020, Loss: 0.8024\n",
            "Train - Accuracy: 0.3823, Precision: 0.4450, Recall: 0.4629, F1: 0.4538\n",
            "Epoch: 030, Loss: 0.7564\n",
            "Train - Accuracy: 0.4602, Precision: 0.5121, Recall: 0.5510, F1: 0.5309\n",
            "Epoch: 040, Loss: 0.7149\n",
            "Train - Accuracy: 0.5286, Precision: 0.5669, Recall: 0.6336, F1: 0.5984\n",
            "Epoch: 050, Loss: 0.6777\n",
            "Train - Accuracy: 0.5932, Precision: 0.6171, Recall: 0.7007, F1: 0.6563\n",
            "Epoch: 060, Loss: 0.6445\n",
            "Train - Accuracy: 0.6451, Precision: 0.6581, Recall: 0.7487, F1: 0.7004\n",
            "Epoch: 070, Loss: 0.6149\n",
            "Train - Accuracy: 0.6825, Precision: 0.6876, Recall: 0.7829, F1: 0.7322\n",
            "Epoch: 080, Loss: 0.5885\n",
            "Train - Accuracy: 0.7159, Precision: 0.7125, Recall: 0.8170, F1: 0.7612\n",
            "Epoch: 090, Loss: 0.5647\n",
            "Train - Accuracy: 0.7417, Precision: 0.7367, Recall: 0.8311, F1: 0.7811\n",
            "Epoch: 100, Loss: 0.5433\n",
            "Train - Accuracy: 0.7655, Precision: 0.7583, Recall: 0.8468, F1: 0.8001\n",
            "Epoch: 110, Loss: 0.5240\n",
            "Train - Accuracy: 0.7827, Precision: 0.7744, Recall: 0.8578, F1: 0.8140\n",
            "Epoch: 120, Loss: 0.5064\n",
            "Train - Accuracy: 0.7932, Precision: 0.7848, Recall: 0.8637, F1: 0.8224\n",
            "Epoch: 130, Loss: 0.4903\n",
            "Train - Accuracy: 0.8078, Precision: 0.7996, Recall: 0.8717, F1: 0.8341\n",
            "Epoch: 140, Loss: 0.4756\n",
            "Train - Accuracy: 0.8198, Precision: 0.8129, Recall: 0.8766, F1: 0.8435\n",
            "Epoch: 150, Loss: 0.4622\n",
            "Train - Accuracy: 0.8295, Precision: 0.8244, Recall: 0.8798, F1: 0.8512\n",
            "Epoch: 160, Loss: 0.4498\n",
            "Train - Accuracy: 0.8365, Precision: 0.8336, Recall: 0.8809, F1: 0.8566\n",
            "Epoch: 170, Loss: 0.4383\n",
            "Train - Accuracy: 0.8412, Precision: 0.8390, Recall: 0.8831, F1: 0.8605\n",
            "Epoch: 180, Loss: 0.4277\n",
            "Train - Accuracy: 0.8460, Precision: 0.8452, Recall: 0.8841, F1: 0.8642\n",
            "Epoch: 190, Loss: 0.4179\n",
            "Train - Accuracy: 0.8515, Precision: 0.8515, Recall: 0.8868, F1: 0.8688\n",
            "Epoch: 200, Loss: 0.4088\n",
            "Train - Accuracy: 0.8543, Precision: 0.8551, Recall: 0.8874, F1: 0.8710\n",
            "Test - Accuracy: 0.8593, Precision: 0.8636, Recall: 0.8932, F1: 0.8782\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Instantiate the model, define the loss function and the optimizer\n",
        "model = LogisticRegression(X_train.shape[1])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "def train_model():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = accuracy_score(labels.cpu(), predicted.cpu())\n",
        "        precision = precision_score(labels.cpu(), predicted.cpu())\n",
        "        recall = recall_score(labels.cpu(), predicted.cpu())\n",
        "        f1 = f1_score(labels.cpu(), predicted.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 201):\n",
        "    loss = train_model()\n",
        "    if epoch % 10 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU1h-yYm8YW8"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a46sDbZ830EX",
        "outputId": "545eda74-f35a-47d3-e34d-edccef713d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Train - Accuracy: 0.6030, Precision: 0.9957, Recall: 0.2850, F1: 0.4431\n",
            "Naive Bayes Test - Accuracy: 0.5798, Precision: 0.9970, Recall: 0.2606, F1: 0.4131\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Initialize and train the Naive Bayes classifier\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train.numpy(), y_train.numpy())\n",
        "\n",
        "# Make predictions on the train set\n",
        "y_train_pred = nb.predict(X_train.numpy())\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_test_pred = nb.predict(X_test.numpy())\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_accuracy = accuracy_score(y_train.numpy(), y_train_pred)\n",
        "train_precision = precision_score(y_train.numpy(), y_train_pred)\n",
        "train_recall = recall_score(y_train.numpy(), y_train_pred)\n",
        "train_f1 = f1_score(y_train.numpy(), y_train_pred)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = accuracy_score(y_test.numpy(), y_test_pred)\n",
        "test_precision = precision_score(y_test.numpy(), y_test_pred)\n",
        "test_recall = recall_score(y_test.numpy(), y_test_pred)\n",
        "test_f1 = f1_score(y_test.numpy(), y_test_pred)\n",
        "\n",
        "print(f'Naive Bayes Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "print(f'Naive Bayes Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L-6LUx58doA"
      },
      "source": [
        "## RESNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_iJTHnMpbML",
        "outputId": "750194ce-3234-43ed-b6c9-b48adf546432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 010, Loss: 0.1572\n",
            "Train - Accuracy: 0.9268, Precision: 0.9122, Recall: 0.9604, F1: 0.9357\n",
            "Epoch: 020, Loss: 0.1197\n",
            "Train - Accuracy: 0.9439, Precision: 0.9311, Recall: 0.9706, F1: 0.9505\n",
            "Epoch: 030, Loss: 0.0793\n",
            "Train - Accuracy: 0.9638, Precision: 0.9528, Recall: 0.9835, F1: 0.9679\n",
            "Epoch: 040, Loss: 0.0474\n",
            "Train - Accuracy: 0.9729, Precision: 0.9594, Recall: 0.9931, F1: 0.9759\n",
            "Epoch: 050, Loss: 0.0304\n",
            "Train - Accuracy: 0.9773, Precision: 0.9633, Recall: 0.9969, F1: 0.9798\n",
            "Epoch: 060, Loss: 0.0228\n",
            "Train - Accuracy: 0.9885, Precision: 0.9831, Recall: 0.9963, F1: 0.9897\n",
            "Epoch: 070, Loss: 0.0208\n",
            "Train - Accuracy: 0.9895, Precision: 0.9906, Recall: 0.9904, F1: 0.9905\n",
            "Epoch: 080, Loss: 0.0195\n",
            "Train - Accuracy: 0.9902, Precision: 0.9869, Recall: 0.9955, F1: 0.9912\n",
            "Epoch: 090, Loss: 0.0189\n",
            "Train - Accuracy: 0.9905, Precision: 0.9884, Recall: 0.9945, F1: 0.9915\n",
            "Epoch: 100, Loss: 0.0181\n",
            "Train - Accuracy: 0.9902, Precision: 0.9892, Recall: 0.9931, F1: 0.9911\n",
            "Epoch: 110, Loss: 0.0230\n",
            "Train - Accuracy: 0.9903, Precision: 0.9900, Recall: 0.9925, F1: 0.9912\n",
            "Epoch: 120, Loss: 0.0195\n",
            "Train - Accuracy: 0.9905, Precision: 0.9896, Recall: 0.9933, F1: 0.9914\n",
            "Epoch: 130, Loss: 0.0182\n",
            "Train - Accuracy: 0.9906, Precision: 0.9890, Recall: 0.9941, F1: 0.9916\n",
            "Epoch: 140, Loss: 0.0178\n",
            "Train - Accuracy: 0.9906, Precision: 0.9896, Recall: 0.9935, F1: 0.9916\n",
            "Epoch: 150, Loss: 0.0177\n",
            "Train - Accuracy: 0.9905, Precision: 0.9884, Recall: 0.9945, F1: 0.9915\n",
            "Epoch: 160, Loss: 0.0176\n",
            "Train - Accuracy: 0.9906, Precision: 0.9896, Recall: 0.9935, F1: 0.9916\n",
            "Epoch: 170, Loss: 0.0210\n",
            "Train - Accuracy: 0.9895, Precision: 0.9896, Recall: 0.9914, F1: 0.9905\n",
            "Epoch: 180, Loss: 0.0192\n",
            "Train - Accuracy: 0.9898, Precision: 0.9924, Recall: 0.9892, F1: 0.9908\n",
            "Epoch: 190, Loss: 0.0181\n",
            "Train - Accuracy: 0.9904, Precision: 0.9882, Recall: 0.9945, F1: 0.9914\n",
            "Epoch: 200, Loss: 0.0178\n",
            "Train - Accuracy: 0.9905, Precision: 0.9878, Recall: 0.9951, F1: 0.9915\n",
            "Test - Accuracy: 0.9629, Precision: 0.9586, Recall: 0.9769, F1: 0.9676\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the ResNet block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.layer(x)\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet model\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.input_layer = nn.Linear(num_features, 64)\n",
        "        self.block1 = ResidualBlock(64)\n",
        "        self.block2 = ResidualBlock(64)\n",
        "        self.block3 = ResidualBlock(64)\n",
        "        self.output_layer = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.input_layer(x))\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.output_layer(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Model parameters\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = 2  # Phishing or not\n",
        "\n",
        "# Instantiate the model\n",
        "model = ResNet(num_features, num_classes)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training the model\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train)\n",
        "    loss = criterion(output, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(data)\n",
        "        pred = output.argmax(dim=1)\n",
        "        accuracy = accuracy_score(labels.cpu(), pred.cpu())\n",
        "        precision = precision_score(labels.cpu(), pred.cpu())\n",
        "        recall = recall_score(labels.cpu(), pred.cpu())\n",
        "        f1 = f1_score(labels.cpu(), pred.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "    if epoch % 10 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ssCzrIrImXr"
      },
      "source": [
        "### 6 TYPES OF RESNETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP5IFf4fFu3X",
        "outputId": "fd39e4d8-c0fb-4550-b831-18cf6d501941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ResNet...\n",
            "Epoch: 010, Loss: 0.1789\n",
            "Train - Accuracy: 0.9244, Precision: 0.9392, Recall: 0.9233, F1: 0.9312\n",
            "Epoch: 020, Loss: 0.1315\n",
            "Train - Accuracy: 0.9439, Precision: 0.9550, Recall: 0.9433, F1: 0.9491\n",
            "Epoch: 030, Loss: 0.1003\n",
            "Train - Accuracy: 0.9557, Precision: 0.9613, Recall: 0.9586, F1: 0.9600\n",
            "Epoch: 040, Loss: 0.0678\n",
            "Train - Accuracy: 0.9703, Precision: 0.9659, Recall: 0.9810, F1: 0.9734\n",
            "Epoch: 050, Loss: 0.0524\n",
            "Train - Accuracy: 0.9802, Precision: 0.9743, Recall: 0.9904, F1: 0.9823\n",
            "Epoch: 060, Loss: 0.0340\n",
            "Train - Accuracy: 0.9869, Precision: 0.9823, Recall: 0.9943, F1: 0.9882\n",
            "Epoch: 070, Loss: 0.0243\n",
            "Train - Accuracy: 0.9884, Precision: 0.9896, Recall: 0.9894, F1: 0.9895\n",
            "Epoch: 080, Loss: 0.0203\n",
            "Train - Accuracy: 0.9874, Precision: 0.9920, Recall: 0.9853, F1: 0.9886\n",
            "Epoch: 090, Loss: 0.0188\n",
            "Train - Accuracy: 0.9891, Precision: 0.9890, Recall: 0.9914, F1: 0.9902\n",
            "Epoch: 100, Loss: 0.0312\n",
            "Train - Accuracy: 0.9887, Precision: 0.9872, Recall: 0.9925, F1: 0.9898\n",
            "Epoch: 110, Loss: 0.0250\n",
            "Train - Accuracy: 0.9893, Precision: 0.9872, Recall: 0.9935, F1: 0.9903\n",
            "Epoch: 120, Loss: 0.0200\n",
            "Train - Accuracy: 0.9902, Precision: 0.9865, Recall: 0.9959, F1: 0.9912\n",
            "Epoch: 130, Loss: 0.0187\n",
            "Train - Accuracy: 0.9903, Precision: 0.9873, Recall: 0.9953, F1: 0.9913\n",
            "Epoch: 140, Loss: 0.0179\n",
            "Train - Accuracy: 0.9906, Precision: 0.9888, Recall: 0.9943, F1: 0.9916\n",
            "Epoch: 150, Loss: 0.0176\n",
            "Train - Accuracy: 0.9906, Precision: 0.9896, Recall: 0.9935, F1: 0.9916\n",
            "Epoch: 160, Loss: 0.0176\n",
            "Train - Accuracy: 0.9905, Precision: 0.9898, Recall: 0.9931, F1: 0.9914\n",
            "Epoch: 170, Loss: 0.0294\n",
            "Train - Accuracy: 0.9895, Precision: 0.9870, Recall: 0.9941, F1: 0.9905\n",
            "Epoch: 180, Loss: 0.0198\n",
            "Train - Accuracy: 0.9895, Precision: 0.9833, Recall: 0.9980, F1: 0.9906\n",
            "Epoch: 190, Loss: 0.0185\n",
            "Train - Accuracy: 0.9905, Precision: 0.9877, Recall: 0.9953, F1: 0.9915\n",
            "Epoch: 200, Loss: 0.0178\n",
            "Train - Accuracy: 0.9906, Precision: 0.9898, Recall: 0.9933, F1: 0.9915\n",
            "Test - Accuracy: 0.9616, Precision: 0.9599, Recall: 0.9729, F1: 0.9664\n",
            "\n",
            "Training ResNetV2...\n",
            "Epoch: 010, Loss: 0.1709\n",
            "Train - Accuracy: 0.9124, Precision: 0.8829, Recall: 0.9706, F1: 0.9247\n",
            "Epoch: 020, Loss: 0.1247\n",
            "Train - Accuracy: 0.9405, Precision: 0.9265, Recall: 0.9696, F1: 0.9476\n",
            "Epoch: 030, Loss: 0.0945\n",
            "Train - Accuracy: 0.9548, Precision: 0.9544, Recall: 0.9645, F1: 0.9594\n",
            "Epoch: 040, Loss: 0.0680\n",
            "Train - Accuracy: 0.9683, Precision: 0.9801, Recall: 0.9625, F1: 0.9712\n",
            "Epoch: 050, Loss: 0.0478\n",
            "Train - Accuracy: 0.9672, Precision: 0.9934, Recall: 0.9472, F1: 0.9697\n",
            "Epoch: 060, Loss: 0.0701\n",
            "Train - Accuracy: 0.9715, Precision: 0.9659, Recall: 0.9833, F1: 0.9745\n",
            "Epoch: 070, Loss: 0.0390\n",
            "Train - Accuracy: 0.9816, Precision: 0.9767, Recall: 0.9904, F1: 0.9835\n",
            "Epoch: 080, Loss: 0.0259\n",
            "Train - Accuracy: 0.9859, Precision: 0.9763, Recall: 0.9988, F1: 0.9874\n",
            "Epoch: 090, Loss: 0.0216\n",
            "Train - Accuracy: 0.9896, Precision: 0.9837, Recall: 0.9978, F1: 0.9907\n",
            "Epoch: 100, Loss: 0.0228\n",
            "Train - Accuracy: 0.9899, Precision: 0.9878, Recall: 0.9941, F1: 0.9910\n",
            "Epoch: 110, Loss: 0.0195\n",
            "Train - Accuracy: 0.9900, Precision: 0.9859, Recall: 0.9963, F1: 0.9911\n",
            "Epoch: 120, Loss: 0.0182\n",
            "Train - Accuracy: 0.9902, Precision: 0.9918, Recall: 0.9904, F1: 0.9911\n",
            "Epoch: 130, Loss: 0.0181\n",
            "Train - Accuracy: 0.9894, Precision: 0.9936, Recall: 0.9871, F1: 0.9904\n",
            "Epoch: 140, Loss: 0.0177\n",
            "Train - Accuracy: 0.9902, Precision: 0.9916, Recall: 0.9906, F1: 0.9911\n",
            "Epoch: 150, Loss: 0.0176\n",
            "Train - Accuracy: 0.9905, Precision: 0.9904, Recall: 0.9925, F1: 0.9914\n",
            "Epoch: 160, Loss: 0.0175\n",
            "Train - Accuracy: 0.9905, Precision: 0.9916, Recall: 0.9912, F1: 0.9914\n",
            "Epoch: 170, Loss: 0.0830\n",
            "Train - Accuracy: 0.9818, Precision: 0.9757, Recall: 0.9918, F1: 0.9837\n",
            "Epoch: 180, Loss: 0.0378\n",
            "Train - Accuracy: 0.9828, Precision: 0.9877, Recall: 0.9812, F1: 0.9844\n",
            "Epoch: 190, Loss: 0.0244\n",
            "Train - Accuracy: 0.9888, Precision: 0.9870, Recall: 0.9929, F1: 0.9899\n",
            "Epoch: 200, Loss: 0.0196\n",
            "Train - Accuracy: 0.9898, Precision: 0.9859, Recall: 0.9959, F1: 0.9909\n",
            "Test - Accuracy: 0.9688, Precision: 0.9604, Recall: 0.9857, F1: 0.9729\n",
            "\n",
            "Training PreActResNet...\n",
            "Epoch: 010, Loss: 0.1806\n",
            "Train - Accuracy: 0.9227, Precision: 0.9483, Recall: 0.9100, F1: 0.9288\n",
            "Epoch: 020, Loss: 0.1319\n",
            "Train - Accuracy: 0.9398, Precision: 0.9571, Recall: 0.9333, F1: 0.9451\n",
            "Epoch: 030, Loss: 0.1013\n",
            "Train - Accuracy: 0.9545, Precision: 0.9487, Recall: 0.9704, F1: 0.9595\n",
            "Epoch: 040, Loss: 0.0650\n",
            "Train - Accuracy: 0.9629, Precision: 0.9407, Recall: 0.9959, F1: 0.9675\n",
            "Epoch: 050, Loss: 0.0585\n",
            "Train - Accuracy: 0.9799, Precision: 0.9760, Recall: 0.9880, F1: 0.9820\n",
            "Epoch: 060, Loss: 0.0339\n",
            "Train - Accuracy: 0.9793, Precision: 0.9705, Recall: 0.9929, F1: 0.9815\n",
            "Epoch: 070, Loss: 0.0252\n",
            "Train - Accuracy: 0.9864, Precision: 0.9824, Recall: 0.9933, F1: 0.9878\n",
            "Epoch: 080, Loss: 0.0228\n",
            "Train - Accuracy: 0.9886, Precision: 0.9908, Recall: 0.9886, F1: 0.9897\n",
            "Epoch: 090, Loss: 0.0199\n",
            "Train - Accuracy: 0.9900, Precision: 0.9916, Recall: 0.9904, F1: 0.9910\n",
            "Epoch: 100, Loss: 0.0184\n",
            "Train - Accuracy: 0.9899, Precision: 0.9918, Recall: 0.9900, F1: 0.9909\n",
            "Epoch: 110, Loss: 0.0239\n",
            "Train - Accuracy: 0.9899, Precision: 0.9918, Recall: 0.9900, F1: 0.9909\n",
            "Epoch: 120, Loss: 0.0188\n",
            "Train - Accuracy: 0.9904, Precision: 0.9878, Recall: 0.9949, F1: 0.9914\n",
            "Epoch: 130, Loss: 0.0180\n",
            "Train - Accuracy: 0.9906, Precision: 0.9884, Recall: 0.9947, F1: 0.9916\n",
            "Epoch: 140, Loss: 0.0178\n",
            "Train - Accuracy: 0.9906, Precision: 0.9888, Recall: 0.9943, F1: 0.9916\n",
            "Epoch: 150, Loss: 0.0176\n",
            "Train - Accuracy: 0.9906, Precision: 0.9886, Recall: 0.9945, F1: 0.9916\n",
            "Epoch: 160, Loss: 0.0175\n",
            "Train - Accuracy: 0.9906, Precision: 0.9894, Recall: 0.9937, F1: 0.9916\n",
            "Epoch: 170, Loss: 0.0237\n",
            "Train - Accuracy: 0.9895, Precision: 0.9936, Recall: 0.9874, F1: 0.9905\n",
            "Epoch: 180, Loss: 0.0185\n",
            "Train - Accuracy: 0.9905, Precision: 0.9888, Recall: 0.9941, F1: 0.9915\n",
            "Epoch: 190, Loss: 0.0179\n",
            "Train - Accuracy: 0.9905, Precision: 0.9873, Recall: 0.9957, F1: 0.9915\n",
            "Epoch: 200, Loss: 0.0177\n",
            "Train - Accuracy: 0.9906, Precision: 0.9886, Recall: 0.9945, F1: 0.9916\n",
            "Test - Accuracy: 0.9656, Precision: 0.9616, Recall: 0.9785, F1: 0.9700\n",
            "\n",
            "Training WideResNet...\n",
            "Epoch: 010, Loss: 0.1851\n",
            "Train - Accuracy: 0.9279, Precision: 0.9220, Recall: 0.9502, F1: 0.9359\n",
            "Epoch: 020, Loss: 0.1493\n",
            "Train - Accuracy: 0.9421, Precision: 0.9388, Recall: 0.9580, F1: 0.9483\n",
            "Epoch: 030, Loss: 0.1252\n",
            "Train - Accuracy: 0.9479, Precision: 0.9510, Recall: 0.9551, F1: 0.9531\n",
            "Epoch: 040, Loss: 0.1014\n",
            "Train - Accuracy: 0.9566, Precision: 0.9597, Recall: 0.9621, F1: 0.9609\n",
            "Epoch: 050, Loss: 0.0721\n",
            "Train - Accuracy: 0.9712, Precision: 0.9704, Recall: 0.9778, F1: 0.9741\n",
            "Epoch: 060, Loss: 0.1416\n",
            "Train - Accuracy: 0.9714, Precision: 0.9667, Recall: 0.9823, F1: 0.9744\n",
            "Epoch: 070, Loss: 0.0612\n",
            "Train - Accuracy: 0.9723, Precision: 0.9597, Recall: 0.9916, F1: 0.9754\n",
            "Epoch: 080, Loss: 0.0384\n",
            "Train - Accuracy: 0.9856, Precision: 0.9814, Recall: 0.9929, F1: 0.9871\n",
            "Epoch: 090, Loss: 0.0253\n",
            "Train - Accuracy: 0.9872, Precision: 0.9811, Recall: 0.9961, F1: 0.9886\n",
            "Epoch: 100, Loss: 0.0241\n",
            "Train - Accuracy: 0.9885, Precision: 0.9819, Recall: 0.9976, F1: 0.9897\n",
            "Epoch: 110, Loss: 0.0201\n",
            "Train - Accuracy: 0.9897, Precision: 0.9880, Recall: 0.9935, F1: 0.9907\n",
            "Epoch: 120, Loss: 0.0186\n",
            "Train - Accuracy: 0.9897, Precision: 0.9902, Recall: 0.9912, F1: 0.9907\n",
            "Epoch: 130, Loss: 0.0181\n",
            "Train - Accuracy: 0.9903, Precision: 0.9904, Recall: 0.9920, F1: 0.9912\n",
            "Epoch: 140, Loss: 0.0181\n",
            "Train - Accuracy: 0.9902, Precision: 0.9918, Recall: 0.9904, F1: 0.9911\n",
            "Epoch: 150, Loss: 0.0177\n",
            "Train - Accuracy: 0.9904, Precision: 0.9896, Recall: 0.9931, F1: 0.9913\n",
            "Epoch: 160, Loss: 0.0177\n",
            "Train - Accuracy: 0.9906, Precision: 0.9894, Recall: 0.9937, F1: 0.9916\n",
            "Epoch: 170, Loss: 0.0178\n",
            "Train - Accuracy: 0.9903, Precision: 0.9914, Recall: 0.9910, F1: 0.9912\n",
            "Epoch: 180, Loss: 0.0416\n",
            "Train - Accuracy: 0.9862, Precision: 0.9799, Recall: 0.9955, F1: 0.9877\n",
            "Epoch: 190, Loss: 0.0251\n",
            "Train - Accuracy: 0.9880, Precision: 0.9829, Recall: 0.9957, F1: 0.9893\n",
            "Epoch: 200, Loss: 0.0204\n",
            "Train - Accuracy: 0.9895, Precision: 0.9906, Recall: 0.9904, F1: 0.9905\n",
            "Test - Accuracy: 0.9643, Precision: 0.9667, Recall: 0.9705, F1: 0.9686\n",
            "\n",
            "Training ResNeXt...\n",
            "Epoch: 010, Loss: 0.1706\n",
            "Train - Accuracy: 0.9253, Precision: 0.9409, Recall: 0.9231, F1: 0.9319\n",
            "Epoch: 020, Loss: 0.1153\n",
            "Train - Accuracy: 0.9483, Precision: 0.9555, Recall: 0.9510, F1: 0.9533\n",
            "Epoch: 030, Loss: 0.0749\n",
            "Train - Accuracy: 0.9665, Precision: 0.9550, Recall: 0.9861, F1: 0.9703\n",
            "Epoch: 040, Loss: 0.0466\n",
            "Train - Accuracy: 0.9790, Precision: 0.9806, Recall: 0.9814, F1: 0.9810\n",
            "Epoch: 050, Loss: 0.0620\n",
            "Train - Accuracy: 0.9768, Precision: 0.9705, Recall: 0.9882, F1: 0.9793\n",
            "Epoch: 060, Loss: 0.0391\n",
            "Train - Accuracy: 0.9839, Precision: 0.9756, Recall: 0.9959, F1: 0.9857\n",
            "Epoch: 070, Loss: 0.0275\n",
            "Train - Accuracy: 0.9874, Precision: 0.9912, Recall: 0.9861, F1: 0.9886\n",
            "Epoch: 080, Loss: 0.0270\n",
            "Train - Accuracy: 0.9891, Precision: 0.9890, Recall: 0.9914, F1: 0.9902\n",
            "Epoch: 090, Loss: 0.0221\n",
            "Train - Accuracy: 0.9890, Precision: 0.9841, Recall: 0.9963, F1: 0.9902\n",
            "Epoch: 100, Loss: 0.0226\n",
            "Train - Accuracy: 0.9894, Precision: 0.9864, Recall: 0.9945, F1: 0.9905\n",
            "Epoch: 110, Loss: 0.0190\n",
            "Train - Accuracy: 0.9902, Precision: 0.9867, Recall: 0.9957, F1: 0.9912\n",
            "Epoch: 120, Loss: 0.0182\n",
            "Train - Accuracy: 0.9905, Precision: 0.9888, Recall: 0.9941, F1: 0.9915\n",
            "Epoch: 130, Loss: 0.0225\n",
            "Train - Accuracy: 0.9898, Precision: 0.9867, Recall: 0.9951, F1: 0.9909\n",
            "Epoch: 140, Loss: 0.0190\n",
            "Train - Accuracy: 0.9903, Precision: 0.9900, Recall: 0.9925, F1: 0.9912\n",
            "Epoch: 150, Loss: 0.0184\n",
            "Train - Accuracy: 0.9900, Precision: 0.9857, Recall: 0.9965, F1: 0.9911\n",
            "Epoch: 160, Loss: 0.0181\n",
            "Train - Accuracy: 0.9905, Precision: 0.9880, Recall: 0.9949, F1: 0.9915\n",
            "Epoch: 170, Loss: 0.0177\n",
            "Train - Accuracy: 0.9906, Precision: 0.9894, Recall: 0.9937, F1: 0.9916\n",
            "Epoch: 180, Loss: 0.0176\n",
            "Train - Accuracy: 0.9905, Precision: 0.9873, Recall: 0.9957, F1: 0.9915\n",
            "Epoch: 190, Loss: 0.0175\n",
            "Train - Accuracy: 0.9906, Precision: 0.9892, Recall: 0.9939, F1: 0.9916\n",
            "Epoch: 200, Loss: 0.0182\n",
            "Train - Accuracy: 0.9902, Precision: 0.9918, Recall: 0.9904, F1: 0.9911\n",
            "Test - Accuracy: 0.9643, Precision: 0.9587, Recall: 0.9793, F1: 0.9689\n",
            "\n",
            "Training DenseNet...\n",
            "Epoch: 010, Loss: 0.1814\n",
            "Train - Accuracy: 0.8866, Precision: 0.9608, Recall: 0.8293, F1: 0.8902\n",
            "Epoch: 020, Loss: 0.1267\n",
            "Train - Accuracy: 0.9437, Precision: 0.9574, Recall: 0.9402, F1: 0.9487\n",
            "Epoch: 030, Loss: 0.0946\n",
            "Train - Accuracy: 0.9540, Precision: 0.9599, Recall: 0.9570, F1: 0.9584\n",
            "Epoch: 040, Loss: 0.0612\n",
            "Train - Accuracy: 0.9714, Precision: 0.9703, Recall: 0.9784, F1: 0.9743\n",
            "Epoch: 050, Loss: 0.0540\n",
            "Train - Accuracy: 0.9770, Precision: 0.9810, Recall: 0.9776, F1: 0.9793\n",
            "Epoch: 060, Loss: 0.0434\n",
            "Train - Accuracy: 0.9844, Precision: 0.9861, Recall: 0.9857, F1: 0.9859\n",
            "Epoch: 070, Loss: 0.0277\n",
            "Train - Accuracy: 0.9850, Precision: 0.9946, Recall: 0.9782, F1: 0.9863\n",
            "Epoch: 080, Loss: 0.0214\n",
            "Train - Accuracy: 0.9861, Precision: 0.9954, Recall: 0.9794, F1: 0.9874\n",
            "Epoch: 090, Loss: 0.0188\n",
            "Train - Accuracy: 0.9894, Precision: 0.9932, Recall: 0.9876, F1: 0.9904\n",
            "Epoch: 100, Loss: 0.0294\n",
            "Train - Accuracy: 0.9887, Precision: 0.9882, Recall: 0.9914, F1: 0.9898\n",
            "Epoch: 110, Loss: 0.0196\n",
            "Train - Accuracy: 0.9903, Precision: 0.9859, Recall: 0.9967, F1: 0.9913\n",
            "Epoch: 120, Loss: 0.0183\n",
            "Train - Accuracy: 0.9906, Precision: 0.9890, Recall: 0.9941, F1: 0.9916\n",
            "Epoch: 130, Loss: 0.0179\n",
            "Train - Accuracy: 0.9904, Precision: 0.9912, Recall: 0.9914, F1: 0.9913\n",
            "Epoch: 140, Loss: 0.0177\n",
            "Train - Accuracy: 0.9905, Precision: 0.9902, Recall: 0.9927, F1: 0.9914\n",
            "Epoch: 150, Loss: 0.0176\n",
            "Train - Accuracy: 0.9906, Precision: 0.9892, Recall: 0.9939, F1: 0.9916\n",
            "Epoch: 160, Loss: 0.0175\n",
            "Train - Accuracy: 0.9906, Precision: 0.9896, Recall: 0.9935, F1: 0.9916\n",
            "Epoch: 170, Loss: 0.1901\n",
            "Train - Accuracy: 0.9819, Precision: 0.9829, Recall: 0.9845, F1: 0.9837\n",
            "Epoch: 180, Loss: 0.0542\n",
            "Train - Accuracy: 0.9775, Precision: 0.9644, Recall: 0.9961, F1: 0.9800\n",
            "Epoch: 190, Loss: 0.0316\n",
            "Train - Accuracy: 0.9865, Precision: 0.9807, Recall: 0.9953, F1: 0.9880\n",
            "Epoch: 200, Loss: 0.0223\n",
            "Train - Accuracy: 0.9877, Precision: 0.9846, Recall: 0.9933, F1: 0.9889\n",
            "Test - Accuracy: 0.9625, Precision: 0.9536, Recall: 0.9817, F1: 0.9674\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the ResNet block for different variants\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.layer(x)\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet model for different variants\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_features, num_classes, block, layers):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.input_layer = nn.Linear(num_features, 64)\n",
        "        self.layer1 = self.make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 64, layers[1])\n",
        "        self.layer3 = self.make_layer(block, 64, layers[2])\n",
        "        self.output_layer = nn.Linear(64, num_classes)\n",
        "\n",
        "    def make_layer(self, block, in_features, blocks):\n",
        "        layers = []\n",
        "        for _ in range(blocks):\n",
        "            layers.append(block(in_features))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.input_layer(x))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.output_layer(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Model parameters\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = 2  # Phishing or not\n",
        "layers = [3, 3, 3]  # Number of layers in each block\n",
        "\n",
        "# Instantiate and train different ResNet variants\n",
        "variants = [\"ResNet\", \"ResNetV2\", \"PreActResNet\", \"WideResNet\", \"ResNeXt\", \"DenseNet\"]\n",
        "for variant in variants:\n",
        "    print(f\"Training {variant}...\")\n",
        "    model = ResNet(num_features, num_classes, ResidualBlock, layers)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_train)\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch % 10 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                output = model(X_train)\n",
        "                pred = output.argmax(dim=1)\n",
        "                train_accuracy = accuracy_score(y_train.cpu(), pred.cpu())\n",
        "                train_precision = precision_score(y_train.cpu(), pred.cpu())\n",
        "                train_recall = recall_score(y_train.cpu(), pred.cpu())\n",
        "                train_f1 = f1_score(y_train.cpu(), pred.cpu())\n",
        "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "            print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "    # Evaluate on test data\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(X_test)\n",
        "        pred = output.argmax(dim=1)\n",
        "        test_accuracy = accuracy_score(y_test.cpu(), pred.cpu())\n",
        "        test_precision = precision_score(y_test.cpu(), pred.cpu())\n",
        "        test_recall = recall_score(y_test.cpu(), pred.cpu())\n",
        "        test_f1 = f1_score(y_test.cpu(), pred.cpu())\n",
        "    print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
