{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Grad Boost IMPLEMENTATION"
      ],
      "metadata": {
        "id": "_DFscmWH7vBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gradient Boosting model\n",
        "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(model, X, y):\n",
        "    predictions = model.predict(X)\n",
        "    accuracy = accuracy_score(y, predictions)\n",
        "    precision = precision_score(y, predictions)\n",
        "    recall = recall_score(y, predictions)\n",
        "    f1 = f1_score(y, predictions)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate on training data\n",
        "train_accuracy, train_precision, train_recall, train_f1 = evaluate(model, X_train, y_train)\n",
        "print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwl9Rh7DsEbE",
        "outputId": "2d674a41-fef1-46f3-d400-9ca02c9213b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Accuracy: 0.9528, Precision: 0.9498, Recall: 0.9659, F1: 0.9578\n",
            "Test - Accuracy: 0.9507, Precision: 0.9491, Recall: 0.9649, F1: 0.9569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM( LINEAR  ) IMPLEMENTATION"
      ],
      "metadata": {
        "id": "w22kzTLl72MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the SVM model\n",
        "model = SVC(kernel='linear', C=1, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(model, X, y):\n",
        "    predictions = model.predict(X)\n",
        "    accuracy = accuracy_score(y, predictions)\n",
        "    precision = precision_score(y, predictions)\n",
        "    recall = recall_score(y, predictions)\n",
        "    f1 = f1_score(y, predictions)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate on training data\n",
        "train_accuracy, train_precision, train_recall, train_f1 = evaluate(model, X_train, y_train)\n",
        "print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-Mymme1smOR",
        "outputId": "cf308bbe-b74a-4339-d21b-3e7f1fb9d8cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Accuracy: 0.9284, Precision: 0.9263, Recall: 0.9461, F1: 0.9361\n",
            "Test - Accuracy: 0.9285, Precision: 0.9262, Recall: 0.9498, F1: 0.9378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN IMPLEMENTATION"
      ],
      "metadata": {
        "id": "16z53om38FlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Add a channel dimension\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)  # Add a channel dimension\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(32 * (X_train.shape[2] // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define the loss function and the optimizer\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "def train_model():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = accuracy_score(labels.cpu(), predicted.cpu())\n",
        "        precision = precision_score(labels.cpu(), predicted.cpu())\n",
        "        recall = recall_score(labels.cpu(), predicted.cpu())\n",
        "        f1 = f1_score(labels.cpu(), predicted.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 201):\n",
        "    loss = train_model()\n",
        "    if epoch % 10 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXzXLa7DtnbD",
        "outputId": "1d7ff802-3e64-44ee-f5f5-70dea9d7036b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Loss: 0.6136\n",
            "Train - Accuracy: 0.7353, Precision: 0.6795, Recall: 0.9890, F1: 0.8055\n",
            "Epoch: 020, Loss: 0.4629\n",
            "Train - Accuracy: 0.8414, Precision: 0.8318, Recall: 0.8947, F1: 0.8621\n",
            "Epoch: 030, Loss: 0.3162\n",
            "Train - Accuracy: 0.8779, Precision: 0.8862, Recall: 0.8945, F1: 0.8904\n",
            "Epoch: 040, Loss: 0.2525\n",
            "Train - Accuracy: 0.8956, Precision: 0.9049, Recall: 0.9070, F1: 0.9060\n",
            "Epoch: 050, Loss: 0.2166\n",
            "Train - Accuracy: 0.9101, Precision: 0.9134, Recall: 0.9255, F1: 0.9194\n",
            "Epoch: 060, Loss: 0.1950\n",
            "Train - Accuracy: 0.9227, Precision: 0.9216, Recall: 0.9404, F1: 0.9309\n",
            "Epoch: 070, Loss: 0.1819\n",
            "Train - Accuracy: 0.9289, Precision: 0.9264, Recall: 0.9470, F1: 0.9365\n",
            "Epoch: 080, Loss: 0.1720\n",
            "Train - Accuracy: 0.9326, Precision: 0.9318, Recall: 0.9478, F1: 0.9397\n",
            "Epoch: 090, Loss: 0.1640\n",
            "Train - Accuracy: 0.9348, Precision: 0.9333, Recall: 0.9502, F1: 0.9417\n",
            "Epoch: 100, Loss: 0.1572\n",
            "Train - Accuracy: 0.9366, Precision: 0.9351, Recall: 0.9517, F1: 0.9433\n",
            "Epoch: 110, Loss: 0.1509\n",
            "Train - Accuracy: 0.9405, Precision: 0.9374, Recall: 0.9565, F1: 0.9469\n",
            "Epoch: 120, Loss: 0.1451\n",
            "Train - Accuracy: 0.9430, Precision: 0.9393, Recall: 0.9592, F1: 0.9491\n",
            "Epoch: 130, Loss: 0.1397\n",
            "Train - Accuracy: 0.9449, Precision: 0.9414, Recall: 0.9604, F1: 0.9508\n",
            "Epoch: 140, Loss: 0.1344\n",
            "Train - Accuracy: 0.9467, Precision: 0.9432, Recall: 0.9619, F1: 0.9524\n",
            "Epoch: 150, Loss: 0.1297\n",
            "Train - Accuracy: 0.9454, Precision: 0.9369, Recall: 0.9665, F1: 0.9515\n",
            "Epoch: 160, Loss: 0.1253\n",
            "Train - Accuracy: 0.9478, Precision: 0.9433, Recall: 0.9637, F1: 0.9534\n",
            "Epoch: 170, Loss: 0.1212\n",
            "Train - Accuracy: 0.9492, Precision: 0.9484, Recall: 0.9606, F1: 0.9545\n",
            "Epoch: 180, Loss: 0.1177\n",
            "Train - Accuracy: 0.9522, Precision: 0.9520, Recall: 0.9623, F1: 0.9571\n",
            "Epoch: 190, Loss: 0.1146\n",
            "Train - Accuracy: 0.9510, Precision: 0.9488, Recall: 0.9637, F1: 0.9562\n",
            "Epoch: 200, Loss: 0.1116\n",
            "Train - Accuracy: 0.9530, Precision: 0.9517, Recall: 0.9641, F1: 0.9578\n",
            "Test - Accuracy: 0.9426, Precision: 0.9386, Recall: 0.9618, F1: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Leaky Relu"
      ],
      "metadata": {
        "id": "SqGLQmtH8MYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Add a channel dimension\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)  # Add a channel dimension\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the CNN model with LeakyReLU\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "        self.fc1 = nn.Linear(32 * (X_train.shape[2] // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.leaky_relu(self.conv1(x)))\n",
        "        x = self.pool(self.leaky_relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define the loss function and the optimizer\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "def train_model():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = accuracy_score(labels.cpu(), predicted.cpu())\n",
        "        precision = precision_score(labels.cpu(), predicted.cpu())\n",
        "        recall = recall_score(labels.cpu(), predicted.cpu())\n",
        "        f1 = f1_score(labels.cpu(), predicted.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 201):\n",
        "    loss = train_model()\n",
        "    if epoch % 10 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR1RWfgnuZ5H",
        "outputId": "4b6be60d-75b1-4e49-cc72-52816e3c8f26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Loss: 0.6390\n",
            "Train - Accuracy: 0.6203, Precision: 0.5936, Recall: 0.9986, F1: 0.7446\n",
            "Epoch: 020, Loss: 0.5150\n",
            "Train - Accuracy: 0.8217, Precision: 0.7955, Recall: 0.9131, F1: 0.8502\n",
            "Epoch: 030, Loss: 0.3543\n",
            "Train - Accuracy: 0.8786, Precision: 0.8741, Recall: 0.9123, F1: 0.8928\n",
            "Epoch: 040, Loss: 0.2661\n",
            "Train - Accuracy: 0.8950, Precision: 0.8974, Recall: 0.9151, F1: 0.9062\n",
            "Epoch: 050, Loss: 0.2270\n",
            "Train - Accuracy: 0.9101, Precision: 0.9138, Recall: 0.9251, F1: 0.9194\n",
            "Epoch: 060, Loss: 0.2013\n",
            "Train - Accuracy: 0.9198, Precision: 0.9159, Recall: 0.9419, F1: 0.9287\n",
            "Epoch: 070, Loss: 0.1849\n",
            "Train - Accuracy: 0.9267, Precision: 0.9225, Recall: 0.9474, F1: 0.9348\n",
            "Epoch: 080, Loss: 0.1741\n",
            "Train - Accuracy: 0.9288, Precision: 0.9265, Recall: 0.9466, F1: 0.9364\n",
            "Epoch: 090, Loss: 0.1650\n",
            "Train - Accuracy: 0.9310, Precision: 0.9289, Recall: 0.9482, F1: 0.9384\n",
            "Epoch: 100, Loss: 0.1567\n",
            "Train - Accuracy: 0.9336, Precision: 0.9319, Recall: 0.9496, F1: 0.9407\n",
            "Epoch: 110, Loss: 0.1494\n",
            "Train - Accuracy: 0.9366, Precision: 0.9340, Recall: 0.9529, F1: 0.9434\n",
            "Epoch: 120, Loss: 0.1430\n",
            "Train - Accuracy: 0.9387, Precision: 0.9360, Recall: 0.9547, F1: 0.9453\n",
            "Epoch: 130, Loss: 0.1373\n",
            "Train - Accuracy: 0.9411, Precision: 0.9392, Recall: 0.9555, F1: 0.9473\n",
            "Epoch: 140, Loss: 0.1321\n",
            "Train - Accuracy: 0.9445, Precision: 0.9465, Recall: 0.9537, F1: 0.9501\n",
            "Epoch: 150, Loss: 0.1276\n",
            "Train - Accuracy: 0.9464, Precision: 0.9469, Recall: 0.9570, F1: 0.9519\n",
            "Epoch: 160, Loss: 0.1234\n",
            "Train - Accuracy: 0.9475, Precision: 0.9456, Recall: 0.9606, F1: 0.9530\n",
            "Epoch: 170, Loss: 0.1197\n",
            "Train - Accuracy: 0.9491, Precision: 0.9482, Recall: 0.9606, F1: 0.9544\n",
            "Epoch: 180, Loss: 0.1162\n",
            "Train - Accuracy: 0.9518, Precision: 0.9480, Recall: 0.9661, F1: 0.9570\n",
            "Epoch: 190, Loss: 0.1129\n",
            "Train - Accuracy: 0.9536, Precision: 0.9543, Recall: 0.9625, F1: 0.9584\n",
            "Epoch: 200, Loss: 0.1100\n",
            "Train - Accuracy: 0.9543, Precision: 0.9525, Recall: 0.9657, F1: 0.9591\n",
            "Test - Accuracy: 0.9435, Precision: 0.9414, Recall: 0.9602, F1: 0.9507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN Classifier"
      ],
      "metadata": {
        "id": "7_G4a3v78QGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Initialize and train the KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train.numpy(), y_train.numpy())\n",
        "\n",
        "# Make predictions on the train set\n",
        "y_train_pred = knn.predict(X_train.numpy())\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_test_pred = knn.predict(X_test.numpy())\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_accuracy = accuracy_score(y_train.numpy(), y_train_pred)\n",
        "train_precision = precision_score(y_train.numpy(), y_train_pred)\n",
        "train_recall = recall_score(y_train.numpy(), y_train_pred)\n",
        "train_f1 = f1_score(y_train.numpy(), y_train_pred)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = accuracy_score(y_test.numpy(), y_test_pred)\n",
        "test_precision = precision_score(y_test.numpy(), y_test_pred)\n",
        "test_recall = recall_score(y_test.numpy(), y_test_pred)\n",
        "test_f1 = f1_score(y_test.numpy(), y_test_pred)\n",
        "\n",
        "print(f'KNN Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "print(f'KNN Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQC0hqNU3FZg",
        "outputId": "a3ca0b50-a849-492a-f229-0c5f4c7c96f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Train - Accuracy: 0.9665, Precision: 0.9658, Recall: 0.9741, F1: 0.9699\n",
            "KNN Test - Accuracy: 0.9408, Precision: 0.9411, Recall: 0.9554, F1: 0.9482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "s5181qdv8To8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Instantiate the model, define the loss function and the optimizer\n",
        "model = LogisticRegression(X_train.shape[1])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "def train_model():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = accuracy_score(labels.cpu(), predicted.cpu())\n",
        "        precision = precision_score(labels.cpu(), predicted.cpu())\n",
        "        recall = recall_score(labels.cpu(), predicted.cpu())\n",
        "        f1 = f1_score(labels.cpu(), predicted.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 201):\n",
        "    loss = train_model()\n",
        "    if epoch % 10 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yChGNkPT3qZ7",
        "outputId": "af3a2d86-a91b-4d2d-87ed-41013fece162"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Loss: 0.8541\n",
            "Train - Accuracy: 0.3405, Precision: 0.4075, Recall: 0.4186, F1: 0.4130\n",
            "Epoch: 020, Loss: 0.8024\n",
            "Train - Accuracy: 0.3823, Precision: 0.4450, Recall: 0.4629, F1: 0.4538\n",
            "Epoch: 030, Loss: 0.7564\n",
            "Train - Accuracy: 0.4602, Precision: 0.5121, Recall: 0.5510, F1: 0.5309\n",
            "Epoch: 040, Loss: 0.7149\n",
            "Train - Accuracy: 0.5286, Precision: 0.5669, Recall: 0.6336, F1: 0.5984\n",
            "Epoch: 050, Loss: 0.6777\n",
            "Train - Accuracy: 0.5932, Precision: 0.6171, Recall: 0.7007, F1: 0.6563\n",
            "Epoch: 060, Loss: 0.6445\n",
            "Train - Accuracy: 0.6451, Precision: 0.6581, Recall: 0.7487, F1: 0.7004\n",
            "Epoch: 070, Loss: 0.6149\n",
            "Train - Accuracy: 0.6825, Precision: 0.6876, Recall: 0.7829, F1: 0.7322\n",
            "Epoch: 080, Loss: 0.5885\n",
            "Train - Accuracy: 0.7159, Precision: 0.7125, Recall: 0.8170, F1: 0.7612\n",
            "Epoch: 090, Loss: 0.5647\n",
            "Train - Accuracy: 0.7417, Precision: 0.7367, Recall: 0.8311, F1: 0.7811\n",
            "Epoch: 100, Loss: 0.5433\n",
            "Train - Accuracy: 0.7655, Precision: 0.7583, Recall: 0.8468, F1: 0.8001\n",
            "Epoch: 110, Loss: 0.5240\n",
            "Train - Accuracy: 0.7827, Precision: 0.7744, Recall: 0.8578, F1: 0.8140\n",
            "Epoch: 120, Loss: 0.5064\n",
            "Train - Accuracy: 0.7932, Precision: 0.7848, Recall: 0.8637, F1: 0.8224\n",
            "Epoch: 130, Loss: 0.4903\n",
            "Train - Accuracy: 0.8078, Precision: 0.7996, Recall: 0.8717, F1: 0.8341\n",
            "Epoch: 140, Loss: 0.4756\n",
            "Train - Accuracy: 0.8198, Precision: 0.8129, Recall: 0.8766, F1: 0.8435\n",
            "Epoch: 150, Loss: 0.4622\n",
            "Train - Accuracy: 0.8295, Precision: 0.8244, Recall: 0.8798, F1: 0.8512\n",
            "Epoch: 160, Loss: 0.4498\n",
            "Train - Accuracy: 0.8365, Precision: 0.8336, Recall: 0.8809, F1: 0.8566\n",
            "Epoch: 170, Loss: 0.4383\n",
            "Train - Accuracy: 0.8412, Precision: 0.8390, Recall: 0.8831, F1: 0.8605\n",
            "Epoch: 180, Loss: 0.4277\n",
            "Train - Accuracy: 0.8460, Precision: 0.8452, Recall: 0.8841, F1: 0.8642\n",
            "Epoch: 190, Loss: 0.4179\n",
            "Train - Accuracy: 0.8515, Precision: 0.8515, Recall: 0.8868, F1: 0.8688\n",
            "Epoch: 200, Loss: 0.4088\n",
            "Train - Accuracy: 0.8543, Precision: 0.8551, Recall: 0.8874, F1: 0.8710\n",
            "Test - Accuracy: 0.8593, Precision: 0.8636, Recall: 0.8932, F1: 0.8782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "xU1h-yYm8YW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Initialize and train the Naive Bayes classifier\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train.numpy(), y_train.numpy())\n",
        "\n",
        "# Make predictions on the train set\n",
        "y_train_pred = nb.predict(X_train.numpy())\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_test_pred = nb.predict(X_test.numpy())\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_accuracy = accuracy_score(y_train.numpy(), y_train_pred)\n",
        "train_precision = precision_score(y_train.numpy(), y_train_pred)\n",
        "train_recall = recall_score(y_train.numpy(), y_train_pred)\n",
        "train_f1 = f1_score(y_train.numpy(), y_train_pred)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = accuracy_score(y_test.numpy(), y_test_pred)\n",
        "test_precision = precision_score(y_test.numpy(), y_test_pred)\n",
        "test_recall = recall_score(y_test.numpy(), y_test_pred)\n",
        "test_f1 = f1_score(y_test.numpy(), y_test_pred)\n",
        "\n",
        "print(f'Naive Bayes Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "print(f'Naive Bayes Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a46sDbZ830EX",
        "outputId": "545eda74-f35a-47d3-e34d-edccef713d68"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Train - Accuracy: 0.6030, Precision: 0.9957, Recall: 0.2850, F1: 0.4431\n",
            "Naive Bayes Test - Accuracy: 0.5798, Precision: 0.9970, Recall: 0.2606, F1: 0.4131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESNET"
      ],
      "metadata": {
        "id": "3L-6LUx58doA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_iJTHnMpbML",
        "outputId": "750194ce-3234-43ed-b6c9-b48adf546432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Loss: 0.1572\n",
            "Train - Accuracy: 0.9268, Precision: 0.9122, Recall: 0.9604, F1: 0.9357\n",
            "Epoch: 020, Loss: 0.1197\n",
            "Train - Accuracy: 0.9439, Precision: 0.9311, Recall: 0.9706, F1: 0.9505\n",
            "Epoch: 030, Loss: 0.0793\n",
            "Train - Accuracy: 0.9638, Precision: 0.9528, Recall: 0.9835, F1: 0.9679\n",
            "Epoch: 040, Loss: 0.0474\n",
            "Train - Accuracy: 0.9729, Precision: 0.9594, Recall: 0.9931, F1: 0.9759\n",
            "Epoch: 050, Loss: 0.0304\n",
            "Train - Accuracy: 0.9773, Precision: 0.9633, Recall: 0.9969, F1: 0.9798\n",
            "Epoch: 060, Loss: 0.0228\n",
            "Train - Accuracy: 0.9885, Precision: 0.9831, Recall: 0.9963, F1: 0.9897\n",
            "Epoch: 070, Loss: 0.0208\n",
            "Train - Accuracy: 0.9895, Precision: 0.9906, Recall: 0.9904, F1: 0.9905\n",
            "Epoch: 080, Loss: 0.0195\n",
            "Train - Accuracy: 0.9902, Precision: 0.9869, Recall: 0.9955, F1: 0.9912\n",
            "Epoch: 090, Loss: 0.0189\n",
            "Train - Accuracy: 0.9905, Precision: 0.9884, Recall: 0.9945, F1: 0.9915\n",
            "Epoch: 100, Loss: 0.0181\n",
            "Train - Accuracy: 0.9902, Precision: 0.9892, Recall: 0.9931, F1: 0.9911\n",
            "Epoch: 110, Loss: 0.0230\n",
            "Train - Accuracy: 0.9903, Precision: 0.9900, Recall: 0.9925, F1: 0.9912\n",
            "Epoch: 120, Loss: 0.0195\n",
            "Train - Accuracy: 0.9905, Precision: 0.9896, Recall: 0.9933, F1: 0.9914\n",
            "Epoch: 130, Loss: 0.0182\n",
            "Train - Accuracy: 0.9906, Precision: 0.9890, Recall: 0.9941, F1: 0.9916\n",
            "Epoch: 140, Loss: 0.0178\n",
            "Train - Accuracy: 0.9906, Precision: 0.9896, Recall: 0.9935, F1: 0.9916\n",
            "Epoch: 150, Loss: 0.0177\n",
            "Train - Accuracy: 0.9905, Precision: 0.9884, Recall: 0.9945, F1: 0.9915\n",
            "Epoch: 160, Loss: 0.0176\n",
            "Train - Accuracy: 0.9906, Precision: 0.9896, Recall: 0.9935, F1: 0.9916\n",
            "Epoch: 170, Loss: 0.0210\n",
            "Train - Accuracy: 0.9895, Precision: 0.9896, Recall: 0.9914, F1: 0.9905\n",
            "Epoch: 180, Loss: 0.0192\n",
            "Train - Accuracy: 0.9898, Precision: 0.9924, Recall: 0.9892, F1: 0.9908\n",
            "Epoch: 190, Loss: 0.0181\n",
            "Train - Accuracy: 0.9904, Precision: 0.9882, Recall: 0.9945, F1: 0.9914\n",
            "Epoch: 200, Loss: 0.0178\n",
            "Train - Accuracy: 0.9905, Precision: 0.9878, Recall: 0.9951, F1: 0.9915\n",
            "Test - Accuracy: 0.9629, Precision: 0.9586, Recall: 0.9769, F1: 0.9676\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the ResNet block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.layer(x)\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet model\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.input_layer = nn.Linear(num_features, 64)\n",
        "        self.block1 = ResidualBlock(64)\n",
        "        self.block2 = ResidualBlock(64)\n",
        "        self.block3 = ResidualBlock(64)\n",
        "        self.output_layer = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.input_layer(x))\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.output_layer(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Model parameters\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = 2  # Phishing or not\n",
        "\n",
        "# Instantiate the model\n",
        "model = ResNet(num_features, num_classes)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training the model\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train)\n",
        "    loss = criterion(output, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(data)\n",
        "        pred = output.argmax(dim=1)\n",
        "        accuracy = accuracy_score(labels.cpu(), pred.cpu())\n",
        "        precision = precision_score(labels.cpu(), pred.cpu())\n",
        "        recall = recall_score(labels.cpu(), pred.cpu())\n",
        "        f1 = f1_score(labels.cpu(), pred.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "    if epoch % 10 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6 TYPES OF RESNETS"
      ],
      "metadata": {
        "id": "6ssCzrIrImXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the ResNet block for different variants\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.layer(x)\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet model for different variants\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_features, num_classes, block, layers):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.input_layer = nn.Linear(num_features, 64)\n",
        "        self.layer1 = self.make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 64, layers[1])\n",
        "        self.layer3 = self.make_layer(block, 64, layers[2])\n",
        "        self.output_layer = nn.Linear(64, num_classes)\n",
        "\n",
        "    def make_layer(self, block, in_features, blocks):\n",
        "        layers = []\n",
        "        for _ in range(blocks):\n",
        "            layers.append(block(in_features))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.input_layer(x))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.output_layer(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Model parameters\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = 2  # Phishing or not\n",
        "layers = [3, 3, 3]  # Number of layers in each block\n",
        "\n",
        "# Instantiate and train different ResNet variants\n",
        "variants = [\"ResNet\", \"ResNetV2\", \"PreActResNet\", \"WideResNet\", \"ResNeXt\", \"DenseNet\"]\n",
        "for variant in variants:\n",
        "    print(f\"Training {variant}...\")\n",
        "    model = ResNet(num_features, num_classes, ResidualBlock, layers)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_train)\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch % 10 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                output = model(X_train)\n",
        "                pred = output.argmax(dim=1)\n",
        "                train_accuracy = accuracy_score(y_train.cpu(), pred.cpu())\n",
        "                train_precision = precision_score(y_train.cpu(), pred.cpu())\n",
        "                train_recall = recall_score(y_train.cpu(), pred.cpu())\n",
        "                train_f1 = f1_score(y_train.cpu(), pred.cpu())\n",
        "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "            print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "    # Evaluate on test data\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(X_test)\n",
        "        pred = output.argmax(dim=1)\n",
        "        test_accuracy = accuracy_score(y_test.cpu(), pred.cpu())\n",
        "        test_precision = precision_score(y_test.cpu(), pred.cpu())\n",
        "        test_recall = recall_score(y_test.cpu(), pred.cpu())\n",
        "        test_f1 = f1_score(y_test.cpu(), pred.cpu())\n",
        "    print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP5IFf4fFu3X",
        "outputId": "fd39e4d8-c0fb-4550-b831-18cf6d501941"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ResNet...\n",
            "Epoch: 010, Loss: 0.1789\n",
            "Train - Accuracy: 0.9244, Precision: 0.9392, Recall: 0.9233, F1: 0.9312\n",
            "Epoch: 020, Loss: 0.1315\n",
            "Train - Accuracy: 0.9439, Precision: 0.9550, Recall: 0.9433, F1: 0.9491\n",
            "Epoch: 030, Loss: 0.1003\n",
            "Train - Accuracy: 0.9557, Precision: 0.9613, Recall: 0.9586, F1: 0.9600\n",
            "Epoch: 040, Loss: 0.0678\n",
            "Train - Accuracy: 0.9703, Precision: 0.9659, Recall: 0.9810, F1: 0.9734\n",
            "Epoch: 050, Loss: 0.0524\n",
            "Train - Accuracy: 0.9802, Precision: 0.9743, Recall: 0.9904, F1: 0.9823\n",
            "Epoch: 060, Loss: 0.0340\n",
            "Train - Accuracy: 0.9869, Precision: 0.9823, Recall: 0.9943, F1: 0.9882\n",
            "Epoch: 070, Loss: 0.0243\n",
            "Train - Accuracy: 0.9884, Precision: 0.9896, Recall: 0.9894, F1: 0.9895\n",
            "Epoch: 080, Loss: 0.0203\n",
            "Train - Accuracy: 0.9874, Precision: 0.9920, Recall: 0.9853, F1: 0.9886\n",
            "Epoch: 090, Loss: 0.0188\n",
            "Train - Accuracy: 0.9891, Precision: 0.9890, Recall: 0.9914, F1: 0.9902\n",
            "Epoch: 100, Loss: 0.0312\n",
            "Train - Accuracy: 0.9887, Precision: 0.9872, Recall: 0.9925, F1: 0.9898\n",
            "Epoch: 110, Loss: 0.0250\n",
            "Train - Accuracy: 0.9893, Precision: 0.9872, Recall: 0.9935, F1: 0.9903\n",
            "Epoch: 120, Loss: 0.0200\n",
            "Train - Accuracy: 0.9902, Precision: 0.9865, Recall: 0.9959, F1: 0.9912\n",
            "Epoch: 130, Loss: 0.0187\n",
            "Train - Accuracy: 0.9903, Precision: 0.9873, Recall: 0.9953, F1: 0.9913\n",
            "Epoch: 140, Loss: 0.0179\n",
            "Train - Accuracy: 0.9906, Precision: 0.9888, Recall: 0.9943, F1: 0.9916\n",
            "Epoch: 150, Loss: 0.0176\n",
            "Train - Accuracy: 0.9906, Precision: 0.9896, Recall: 0.9935, F1: 0.9916\n",
            "Epoch: 160, Loss: 0.0176\n",
            "Train - Accuracy: 0.9905, Precision: 0.9898, Recall: 0.9931, F1: 0.9914\n",
            "Epoch: 170, Loss: 0.0294\n",
            "Train - Accuracy: 0.9895, Precision: 0.9870, Recall: 0.9941, F1: 0.9905\n",
            "Epoch: 180, Loss: 0.0198\n",
            "Train - Accuracy: 0.9895, Precision: 0.9833, Recall: 0.9980, F1: 0.9906\n",
            "Epoch: 190, Loss: 0.0185\n",
            "Train - Accuracy: 0.9905, Precision: 0.9877, Recall: 0.9953, F1: 0.9915\n",
            "Epoch: 200, Loss: 0.0178\n",
            "Train - Accuracy: 0.9906, Precision: 0.9898, Recall: 0.9933, F1: 0.9915\n",
            "Test - Accuracy: 0.9616, Precision: 0.9599, Recall: 0.9729, F1: 0.9664\n",
            "\n",
            "Training ResNetV2...\n",
            "Epoch: 010, Loss: 0.1709\n",
            "Train - Accuracy: 0.9124, Precision: 0.8829, Recall: 0.9706, F1: 0.9247\n",
            "Epoch: 020, Loss: 0.1247\n",
            "Train - Accuracy: 0.9405, Precision: 0.9265, Recall: 0.9696, F1: 0.9476\n",
            "Epoch: 030, Loss: 0.0945\n",
            "Train - Accuracy: 0.9548, Precision: 0.9544, Recall: 0.9645, F1: 0.9594\n",
            "Epoch: 040, Loss: 0.0680\n",
            "Train - Accuracy: 0.9683, Precision: 0.9801, Recall: 0.9625, F1: 0.9712\n",
            "Epoch: 050, Loss: 0.0478\n",
            "Train - Accuracy: 0.9672, Precision: 0.9934, Recall: 0.9472, F1: 0.9697\n",
            "Epoch: 060, Loss: 0.0701\n",
            "Train - Accuracy: 0.9715, Precision: 0.9659, Recall: 0.9833, F1: 0.9745\n",
            "Epoch: 070, Loss: 0.0390\n",
            "Train - Accuracy: 0.9816, Precision: 0.9767, Recall: 0.9904, F1: 0.9835\n",
            "Epoch: 080, Loss: 0.0259\n",
            "Train - Accuracy: 0.9859, Precision: 0.9763, Recall: 0.9988, F1: 0.9874\n",
            "Epoch: 090, Loss: 0.0216\n",
            "Train - Accuracy: 0.9896, Precision: 0.9837, Recall: 0.9978, F1: 0.9907\n",
            "Epoch: 100, Loss: 0.0228\n",
            "Train - Accuracy: 0.9899, Precision: 0.9878, Recall: 0.9941, F1: 0.9910\n",
            "Epoch: 110, Loss: 0.0195\n",
            "Train - Accuracy: 0.9900, Precision: 0.9859, Recall: 0.9963, F1: 0.9911\n",
            "Epoch: 120, Loss: 0.0182\n",
            "Train - Accuracy: 0.9902, Precision: 0.9918, Recall: 0.9904, F1: 0.9911\n",
            "Epoch: 130, Loss: 0.0181\n",
            "Train - Accuracy: 0.9894, Precision: 0.9936, Recall: 0.9871, F1: 0.9904\n",
            "Epoch: 140, Loss: 0.0177\n",
            "Train - Accuracy: 0.9902, Precision: 0.9916, Recall: 0.9906, F1: 0.9911\n",
            "Epoch: 150, Loss: 0.0176\n",
            "Train - Accuracy: 0.9905, Precision: 0.9904, Recall: 0.9925, F1: 0.9914\n",
            "Epoch: 160, Loss: 0.0175\n",
            "Train - Accuracy: 0.9905, Precision: 0.9916, Recall: 0.9912, F1: 0.9914\n",
            "Epoch: 170, Loss: 0.0830\n",
            "Train - Accuracy: 0.9818, Precision: 0.9757, Recall: 0.9918, F1: 0.9837\n",
            "Epoch: 180, Loss: 0.0378\n",
            "Train - Accuracy: 0.9828, Precision: 0.9877, Recall: 0.9812, F1: 0.9844\n",
            "Epoch: 190, Loss: 0.0244\n",
            "Train - Accuracy: 0.9888, Precision: 0.9870, Recall: 0.9929, F1: 0.9899\n",
            "Epoch: 200, Loss: 0.0196\n",
            "Train - Accuracy: 0.9898, Precision: 0.9859, Recall: 0.9959, F1: 0.9909\n",
            "Test - Accuracy: 0.9688, Precision: 0.9604, Recall: 0.9857, F1: 0.9729\n",
            "\n",
            "Training PreActResNet...\n",
            "Epoch: 010, Loss: 0.1806\n",
            "Train - Accuracy: 0.9227, Precision: 0.9483, Recall: 0.9100, F1: 0.9288\n",
            "Epoch: 020, Loss: 0.1319\n",
            "Train - Accuracy: 0.9398, Precision: 0.9571, Recall: 0.9333, F1: 0.9451\n",
            "Epoch: 030, Loss: 0.1013\n",
            "Train - Accuracy: 0.9545, Precision: 0.9487, Recall: 0.9704, F1: 0.9595\n",
            "Epoch: 040, Loss: 0.0650\n",
            "Train - Accuracy: 0.9629, Precision: 0.9407, Recall: 0.9959, F1: 0.9675\n",
            "Epoch: 050, Loss: 0.0585\n",
            "Train - Accuracy: 0.9799, Precision: 0.9760, Recall: 0.9880, F1: 0.9820\n",
            "Epoch: 060, Loss: 0.0339\n",
            "Train - Accuracy: 0.9793, Precision: 0.9705, Recall: 0.9929, F1: 0.9815\n",
            "Epoch: 070, Loss: 0.0252\n",
            "Train - Accuracy: 0.9864, Precision: 0.9824, Recall: 0.9933, F1: 0.9878\n",
            "Epoch: 080, Loss: 0.0228\n",
            "Train - Accuracy: 0.9886, Precision: 0.9908, Recall: 0.9886, F1: 0.9897\n",
            "Epoch: 090, Loss: 0.0199\n",
            "Train - Accuracy: 0.9900, Precision: 0.9916, Recall: 0.9904, F1: 0.9910\n",
            "Epoch: 100, Loss: 0.0184\n",
            "Train - Accuracy: 0.9899, Precision: 0.9918, Recall: 0.9900, F1: 0.9909\n",
            "Epoch: 110, Loss: 0.0239\n",
            "Train - Accuracy: 0.9899, Precision: 0.9918, Recall: 0.9900, F1: 0.9909\n",
            "Epoch: 120, Loss: 0.0188\n",
            "Train - Accuracy: 0.9904, Precision: 0.9878, Recall: 0.9949, F1: 0.9914\n",
            "Epoch: 130, Loss: 0.0180\n",
            "Train - Accuracy: 0.9906, Precision: 0.9884, Recall: 0.9947, F1: 0.9916\n",
            "Epoch: 140, Loss: 0.0178\n",
            "Train - Accuracy: 0.9906, Precision: 0.9888, Recall: 0.9943, F1: 0.9916\n",
            "Epoch: 150, Loss: 0.0176\n",
            "Train - Accuracy: 0.9906, Precision: 0.9886, Recall: 0.9945, F1: 0.9916\n",
            "Epoch: 160, Loss: 0.0175\n",
            "Train - Accuracy: 0.9906, Precision: 0.9894, Recall: 0.9937, F1: 0.9916\n",
            "Epoch: 170, Loss: 0.0237\n",
            "Train - Accuracy: 0.9895, Precision: 0.9936, Recall: 0.9874, F1: 0.9905\n",
            "Epoch: 180, Loss: 0.0185\n",
            "Train - Accuracy: 0.9905, Precision: 0.9888, Recall: 0.9941, F1: 0.9915\n",
            "Epoch: 190, Loss: 0.0179\n",
            "Train - Accuracy: 0.9905, Precision: 0.9873, Recall: 0.9957, F1: 0.9915\n",
            "Epoch: 200, Loss: 0.0177\n",
            "Train - Accuracy: 0.9906, Precision: 0.9886, Recall: 0.9945, F1: 0.9916\n",
            "Test - Accuracy: 0.9656, Precision: 0.9616, Recall: 0.9785, F1: 0.9700\n",
            "\n",
            "Training WideResNet...\n",
            "Epoch: 010, Loss: 0.1851\n",
            "Train - Accuracy: 0.9279, Precision: 0.9220, Recall: 0.9502, F1: 0.9359\n",
            "Epoch: 020, Loss: 0.1493\n",
            "Train - Accuracy: 0.9421, Precision: 0.9388, Recall: 0.9580, F1: 0.9483\n",
            "Epoch: 030, Loss: 0.1252\n",
            "Train - Accuracy: 0.9479, Precision: 0.9510, Recall: 0.9551, F1: 0.9531\n",
            "Epoch: 040, Loss: 0.1014\n",
            "Train - Accuracy: 0.9566, Precision: 0.9597, Recall: 0.9621, F1: 0.9609\n",
            "Epoch: 050, Loss: 0.0721\n",
            "Train - Accuracy: 0.9712, Precision: 0.9704, Recall: 0.9778, F1: 0.9741\n",
            "Epoch: 060, Loss: 0.1416\n",
            "Train - Accuracy: 0.9714, Precision: 0.9667, Recall: 0.9823, F1: 0.9744\n",
            "Epoch: 070, Loss: 0.0612\n",
            "Train - Accuracy: 0.9723, Precision: 0.9597, Recall: 0.9916, F1: 0.9754\n",
            "Epoch: 080, Loss: 0.0384\n",
            "Train - Accuracy: 0.9856, Precision: 0.9814, Recall: 0.9929, F1: 0.9871\n",
            "Epoch: 090, Loss: 0.0253\n",
            "Train - Accuracy: 0.9872, Precision: 0.9811, Recall: 0.9961, F1: 0.9886\n",
            "Epoch: 100, Loss: 0.0241\n",
            "Train - Accuracy: 0.9885, Precision: 0.9819, Recall: 0.9976, F1: 0.9897\n",
            "Epoch: 110, Loss: 0.0201\n",
            "Train - Accuracy: 0.9897, Precision: 0.9880, Recall: 0.9935, F1: 0.9907\n",
            "Epoch: 120, Loss: 0.0186\n",
            "Train - Accuracy: 0.9897, Precision: 0.9902, Recall: 0.9912, F1: 0.9907\n",
            "Epoch: 130, Loss: 0.0181\n",
            "Train - Accuracy: 0.9903, Precision: 0.9904, Recall: 0.9920, F1: 0.9912\n",
            "Epoch: 140, Loss: 0.0181\n",
            "Train - Accuracy: 0.9902, Precision: 0.9918, Recall: 0.9904, F1: 0.9911\n",
            "Epoch: 150, Loss: 0.0177\n",
            "Train - Accuracy: 0.9904, Precision: 0.9896, Recall: 0.9931, F1: 0.9913\n",
            "Epoch: 160, Loss: 0.0177\n",
            "Train - Accuracy: 0.9906, Precision: 0.9894, Recall: 0.9937, F1: 0.9916\n",
            "Epoch: 170, Loss: 0.0178\n",
            "Train - Accuracy: 0.9903, Precision: 0.9914, Recall: 0.9910, F1: 0.9912\n",
            "Epoch: 180, Loss: 0.0416\n",
            "Train - Accuracy: 0.9862, Precision: 0.9799, Recall: 0.9955, F1: 0.9877\n",
            "Epoch: 190, Loss: 0.0251\n",
            "Train - Accuracy: 0.9880, Precision: 0.9829, Recall: 0.9957, F1: 0.9893\n",
            "Epoch: 200, Loss: 0.0204\n",
            "Train - Accuracy: 0.9895, Precision: 0.9906, Recall: 0.9904, F1: 0.9905\n",
            "Test - Accuracy: 0.9643, Precision: 0.9667, Recall: 0.9705, F1: 0.9686\n",
            "\n",
            "Training ResNeXt...\n",
            "Epoch: 010, Loss: 0.1706\n",
            "Train - Accuracy: 0.9253, Precision: 0.9409, Recall: 0.9231, F1: 0.9319\n",
            "Epoch: 020, Loss: 0.1153\n",
            "Train - Accuracy: 0.9483, Precision: 0.9555, Recall: 0.9510, F1: 0.9533\n",
            "Epoch: 030, Loss: 0.0749\n",
            "Train - Accuracy: 0.9665, Precision: 0.9550, Recall: 0.9861, F1: 0.9703\n",
            "Epoch: 040, Loss: 0.0466\n",
            "Train - Accuracy: 0.9790, Precision: 0.9806, Recall: 0.9814, F1: 0.9810\n",
            "Epoch: 050, Loss: 0.0620\n",
            "Train - Accuracy: 0.9768, Precision: 0.9705, Recall: 0.9882, F1: 0.9793\n",
            "Epoch: 060, Loss: 0.0391\n",
            "Train - Accuracy: 0.9839, Precision: 0.9756, Recall: 0.9959, F1: 0.9857\n",
            "Epoch: 070, Loss: 0.0275\n",
            "Train - Accuracy: 0.9874, Precision: 0.9912, Recall: 0.9861, F1: 0.9886\n",
            "Epoch: 080, Loss: 0.0270\n",
            "Train - Accuracy: 0.9891, Precision: 0.9890, Recall: 0.9914, F1: 0.9902\n",
            "Epoch: 090, Loss: 0.0221\n",
            "Train - Accuracy: 0.9890, Precision: 0.9841, Recall: 0.9963, F1: 0.9902\n",
            "Epoch: 100, Loss: 0.0226\n",
            "Train - Accuracy: 0.9894, Precision: 0.9864, Recall: 0.9945, F1: 0.9905\n",
            "Epoch: 110, Loss: 0.0190\n",
            "Train - Accuracy: 0.9902, Precision: 0.9867, Recall: 0.9957, F1: 0.9912\n",
            "Epoch: 120, Loss: 0.0182\n",
            "Train - Accuracy: 0.9905, Precision: 0.9888, Recall: 0.9941, F1: 0.9915\n",
            "Epoch: 130, Loss: 0.0225\n",
            "Train - Accuracy: 0.9898, Precision: 0.9867, Recall: 0.9951, F1: 0.9909\n",
            "Epoch: 140, Loss: 0.0190\n",
            "Train - Accuracy: 0.9903, Precision: 0.9900, Recall: 0.9925, F1: 0.9912\n",
            "Epoch: 150, Loss: 0.0184\n",
            "Train - Accuracy: 0.9900, Precision: 0.9857, Recall: 0.9965, F1: 0.9911\n",
            "Epoch: 160, Loss: 0.0181\n",
            "Train - Accuracy: 0.9905, Precision: 0.9880, Recall: 0.9949, F1: 0.9915\n",
            "Epoch: 170, Loss: 0.0177\n",
            "Train - Accuracy: 0.9906, Precision: 0.9894, Recall: 0.9937, F1: 0.9916\n",
            "Epoch: 180, Loss: 0.0176\n",
            "Train - Accuracy: 0.9905, Precision: 0.9873, Recall: 0.9957, F1: 0.9915\n",
            "Epoch: 190, Loss: 0.0175\n",
            "Train - Accuracy: 0.9906, Precision: 0.9892, Recall: 0.9939, F1: 0.9916\n",
            "Epoch: 200, Loss: 0.0182\n",
            "Train - Accuracy: 0.9902, Precision: 0.9918, Recall: 0.9904, F1: 0.9911\n",
            "Test - Accuracy: 0.9643, Precision: 0.9587, Recall: 0.9793, F1: 0.9689\n",
            "\n",
            "Training DenseNet...\n",
            "Epoch: 010, Loss: 0.1814\n",
            "Train - Accuracy: 0.8866, Precision: 0.9608, Recall: 0.8293, F1: 0.8902\n",
            "Epoch: 020, Loss: 0.1267\n",
            "Train - Accuracy: 0.9437, Precision: 0.9574, Recall: 0.9402, F1: 0.9487\n",
            "Epoch: 030, Loss: 0.0946\n",
            "Train - Accuracy: 0.9540, Precision: 0.9599, Recall: 0.9570, F1: 0.9584\n",
            "Epoch: 040, Loss: 0.0612\n",
            "Train - Accuracy: 0.9714, Precision: 0.9703, Recall: 0.9784, F1: 0.9743\n",
            "Epoch: 050, Loss: 0.0540\n",
            "Train - Accuracy: 0.9770, Precision: 0.9810, Recall: 0.9776, F1: 0.9793\n",
            "Epoch: 060, Loss: 0.0434\n",
            "Train - Accuracy: 0.9844, Precision: 0.9861, Recall: 0.9857, F1: 0.9859\n",
            "Epoch: 070, Loss: 0.0277\n",
            "Train - Accuracy: 0.9850, Precision: 0.9946, Recall: 0.9782, F1: 0.9863\n",
            "Epoch: 080, Loss: 0.0214\n",
            "Train - Accuracy: 0.9861, Precision: 0.9954, Recall: 0.9794, F1: 0.9874\n",
            "Epoch: 090, Loss: 0.0188\n",
            "Train - Accuracy: 0.9894, Precision: 0.9932, Recall: 0.9876, F1: 0.9904\n",
            "Epoch: 100, Loss: 0.0294\n",
            "Train - Accuracy: 0.9887, Precision: 0.9882, Recall: 0.9914, F1: 0.9898\n",
            "Epoch: 110, Loss: 0.0196\n",
            "Train - Accuracy: 0.9903, Precision: 0.9859, Recall: 0.9967, F1: 0.9913\n",
            "Epoch: 120, Loss: 0.0183\n",
            "Train - Accuracy: 0.9906, Precision: 0.9890, Recall: 0.9941, F1: 0.9916\n",
            "Epoch: 130, Loss: 0.0179\n",
            "Train - Accuracy: 0.9904, Precision: 0.9912, Recall: 0.9914, F1: 0.9913\n",
            "Epoch: 140, Loss: 0.0177\n",
            "Train - Accuracy: 0.9905, Precision: 0.9902, Recall: 0.9927, F1: 0.9914\n",
            "Epoch: 150, Loss: 0.0176\n",
            "Train - Accuracy: 0.9906, Precision: 0.9892, Recall: 0.9939, F1: 0.9916\n",
            "Epoch: 160, Loss: 0.0175\n",
            "Train - Accuracy: 0.9906, Precision: 0.9896, Recall: 0.9935, F1: 0.9916\n",
            "Epoch: 170, Loss: 0.1901\n",
            "Train - Accuracy: 0.9819, Precision: 0.9829, Recall: 0.9845, F1: 0.9837\n",
            "Epoch: 180, Loss: 0.0542\n",
            "Train - Accuracy: 0.9775, Precision: 0.9644, Recall: 0.9961, F1: 0.9800\n",
            "Epoch: 190, Loss: 0.0316\n",
            "Train - Accuracy: 0.9865, Precision: 0.9807, Recall: 0.9953, F1: 0.9880\n",
            "Epoch: 200, Loss: 0.0223\n",
            "Train - Accuracy: 0.9877, Precision: 0.9846, Recall: 0.9933, F1: 0.9889\n",
            "Test - Accuracy: 0.9625, Precision: 0.9536, Recall: 0.9817, F1: 0.9674\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlockV2(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlockV2, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.BatchNorm1d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features, in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.layer(x)\n",
        "        out += residual\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "_QecZAMmjuGu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PreActResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(PreActResidualBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm1d(in_features)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc1 = nn.Linear(in_features, in_features)\n",
        "        self.bn2 = nn.BatchNorm1d(in_features)\n",
        "        self.fc2 = nn.Linear(in_features, in_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(x))\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(self.bn2(out))\n",
        "        out = self.fc2(out)\n",
        "        out += x\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "b80UGVJ2jvyY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PreActResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(PreActResidualBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm1d(in_features)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc1 = nn.Linear(in_features, in_features)\n",
        "        self.bn2 = nn.BatchNorm1d(in_features)\n",
        "        self.fc2 = nn.Linear(in_features, in_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(x))\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(self.bn2(out))\n",
        "        out = self.fc2(out)\n",
        "        out += x\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "27-PY-E7jx-g"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WideResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features, widen_factor=2):\n",
        "        super(WideResidualBlock, self).__init__()\n",
        "        widened_features = in_features * widen_factor\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(in_features, widened_features),\n",
        "            nn.BatchNorm1d(widened_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(widened_features, in_features),\n",
        "            nn.BatchNorm1d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.layer(x)\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "EK2tISIkjx4u"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, in_features, growth_rate=32):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.BatchNorm1d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features, growth_rate)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer(x)\n",
        "        out = torch.cat([x, out], dim=1)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "EpHI0_Q-kChp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNeXtBlock(nn.Module):\n",
        "    def __init__(self, in_features, cardinality=4, bottleneck_width=64):\n",
        "        super(ResNeXtBlock, self).__init__()\n",
        "        D = cardinality * bottleneck_width\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(in_features, D),\n",
        "            nn.BatchNorm1d(D),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(D, in_features),\n",
        "            nn.BatchNorm1d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.layer(x)\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "hD6yXVNRjxxI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ePUr7Cayjxlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the training and evaluation functions\n",
        "def train(model, optimizer, criterion, X_train, y_train):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train)\n",
        "    loss = criterion(output, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(model, X_data, y_data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(X_data)\n",
        "        pred = output.argmax(dim=1)\n",
        "        accuracy = accuracy_score(y_data.cpu(), pred.cpu())\n",
        "        precision = precision_score(y_data.cpu(), pred.cpu())\n",
        "        recall = recall_score(y_data.cpu(), pred.cpu())\n",
        "        f1 = f1_score(y_data.cpu(), pred.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Function to train and evaluate a model\n",
        "def train_and_evaluate(model, X_train, y_train, X_test, y_test, epochs=200):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    train_precisions = []\n",
        "    train_recalls = []\n",
        "    train_f1s = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        loss = train(model, optimizer, criterion, X_train, y_train)\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            train_accuracy, train_precision, train_recall, train_f1 = evaluate(model, X_train, y_train)\n",
        "            train_accuracies.append(train_accuracy)\n",
        "            train_precisions.append(train_precision)\n",
        "            train_recalls.append(train_recall)\n",
        "            train_f1s.append(train_f1)\n",
        "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "            print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "    test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, X_test, y_test)\n",
        "    print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n",
        "\n",
        "    return train_losses, train_accuracies, train_precisions, train_recalls, train_f1s, test_accuracy, test_precision, test_recall, test_f1\n",
        "\n",
        "# Store the results for each variant\n",
        "results = {}\n",
        "\n",
        "# List of variants to train\n",
        "variants = [\"ResNet\", \"ResNetV2\", \"PreActResNet\", \"WideResNet\", \"ResNeXt\", \"DenseNet\"]\n",
        "\n",
        "for variant in variants:\n",
        "    print(f\"Training {variant}...\")\n",
        "    if variant == \"ResNet\":\n",
        "        model = ResNet(num_features, num_classes, ResidualBlock, layers)\n",
        "    elif variant == \"ResNetV2\":\n",
        "        model = ResNet(num_features, num_classes, ResidualBlockV2, layers)\n",
        "    elif variant == \"PreActResNet\":\n",
        "        model = PreActResNet(num_features, num_classes, PreActResidualBlock, layers)\n",
        "    elif variant == \"WideResNet\":\n",
        "        model = WideResNet(num_features, num_classes, WideResidualBlock, layers)\n",
        "    elif variant == \"ResNeXt\":\n",
        "        model = ResNeXt(num_features, num_classes, ResNeXtBlock, layers)\n",
        "    elif variant == \"DenseNet\":\n",
        "        model = DenseNet(num_features, num_classes, DenseBlock, layers)\n",
        "\n",
        "    losses, accuracies, precisions, recalls, f1s, test_acc, test_prec, test_rec, test_f1 = train_and_evaluate(model, X_train, y_train, X_test, y_test)\n",
        "    results[variant] = {\n",
        "        'losses': losses,\n",
        "        'accuracies': accuracies,\n",
        "        'precisions': precisions,\n",
        "        'recalls': recalls,\n",
        "        'f1s': f1s,\n",
        "        'test_acc': test_acc,\n",
        "        'test_prec': test_prec,\n",
        "        'test_rec': test_rec,\n",
        "        'test_f1': test_f1\n",
        "    }\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Plot training loss\n",
        "plt.subplot(2, 2, 1)\n",
        "for variant in variants:\n",
        "    plt.plot(results[variant]['losses'], label=variant)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training accuracy\n",
        "plt.subplot(2, 2, 2)\n",
        "for variant in variants:\n",
        "    plt.plot(range(10, 201, 10), results[variant]['accuracies'], label=variant)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training precision\n",
        "plt.subplot(2, 2, 3)\n",
        "for variant in variants:\n",
        "    plt.plot(range(10, 201, 10), results[variant]['precisions'], label=variant)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Training Precision')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training F1 score\n",
        "plt.subplot(2, 2, 4)\n",
        "for variant in variants:\n",
        "    plt.plot(range(10, 201, 10), results[variant]['f1s'], label=variant)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Training F1 Score')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BKY1ff5wises",
        "outputId": "375030b4-2985-401b-9a09-ef75c8cd36f8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ResNet...\n",
            "Epoch: 010, Loss: 0.1730\n",
            "Train - Accuracy: 0.8792, Precision: 0.9597, Recall: 0.8164, F1: 0.8823\n",
            "Epoch: 020, Loss: 0.1194\n",
            "Train - Accuracy: 0.9311, Precision: 0.9631, Recall: 0.9106, F1: 0.9361\n",
            "Epoch: 030, Loss: 0.0804\n",
            "Train - Accuracy: 0.9631, Precision: 0.9683, Recall: 0.9651, F1: 0.9667\n",
            "Epoch: 040, Loss: 0.0497\n",
            "Train - Accuracy: 0.9770, Precision: 0.9780, Recall: 0.9806, F1: 0.9793\n",
            "Epoch: 050, Loss: 0.0349\n",
            "Train - Accuracy: 0.9833, Precision: 0.9762, Recall: 0.9941, F1: 0.9850\n",
            "Epoch: 060, Loss: 0.0252\n",
            "Train - Accuracy: 0.9885, Precision: 0.9847, Recall: 0.9947, F1: 0.9896\n",
            "Epoch: 070, Loss: 0.0209\n",
            "Train - Accuracy: 0.9898, Precision: 0.9882, Recall: 0.9935, F1: 0.9908\n",
            "Epoch: 080, Loss: 0.0189\n",
            "Train - Accuracy: 0.9905, Precision: 0.9894, Recall: 0.9935, F1: 0.9914\n",
            "Epoch: 090, Loss: 0.0189\n",
            "Train - Accuracy: 0.9893, Precision: 0.9912, Recall: 0.9894, F1: 0.9903\n",
            "Epoch: 100, Loss: 0.0181\n",
            "Train - Accuracy: 0.9904, Precision: 0.9876, Recall: 0.9951, F1: 0.9914\n",
            "Epoch: 110, Loss: 0.0178\n",
            "Train - Accuracy: 0.9906, Precision: 0.9884, Recall: 0.9947, F1: 0.9916\n",
            "Epoch: 120, Loss: 0.0186\n",
            "Train - Accuracy: 0.9903, Precision: 0.9888, Recall: 0.9937, F1: 0.9912\n",
            "Epoch: 130, Loss: 0.0183\n",
            "Train - Accuracy: 0.9903, Precision: 0.9861, Recall: 0.9965, F1: 0.9913\n",
            "Epoch: 140, Loss: 0.0178\n",
            "Train - Accuracy: 0.9906, Precision: 0.9896, Recall: 0.9935, F1: 0.9916\n",
            "Epoch: 150, Loss: 0.0176\n",
            "Train - Accuracy: 0.9903, Precision: 0.9922, Recall: 0.9902, F1: 0.9912\n",
            "Epoch: 160, Loss: 0.0176\n",
            "Train - Accuracy: 0.9905, Precision: 0.9886, Recall: 0.9943, F1: 0.9915\n",
            "Epoch: 170, Loss: 0.0211\n",
            "Train - Accuracy: 0.9905, Precision: 0.9886, Recall: 0.9943, F1: 0.9915\n",
            "Epoch: 180, Loss: 0.0183\n",
            "Train - Accuracy: 0.9902, Precision: 0.9902, Recall: 0.9920, F1: 0.9911\n",
            "Epoch: 190, Loss: 0.0179\n",
            "Train - Accuracy: 0.9905, Precision: 0.9910, Recall: 0.9918, F1: 0.9914\n",
            "Epoch: 200, Loss: 0.0176\n",
            "Train - Accuracy: 0.9906, Precision: 0.9900, Recall: 0.9931, F1: 0.9915\n",
            "Test - Accuracy: 0.9656, Precision: 0.9616, Recall: 0.9785, F1: 0.9700\n",
            "Training ResNetV2...\n",
            "Epoch: 010, Loss: 0.2017\n",
            "Train - Accuracy: 0.9288, Precision: 0.9087, Recall: 0.9688, F1: 0.9378\n",
            "Epoch: 020, Loss: 0.1457\n",
            "Train - Accuracy: 0.9443, Precision: 0.9391, Recall: 0.9619, F1: 0.9503\n",
            "Epoch: 030, Loss: 0.1157\n",
            "Train - Accuracy: 0.9542, Precision: 0.9496, Recall: 0.9688, F1: 0.9591\n",
            "Epoch: 040, Loss: 0.0921\n",
            "Train - Accuracy: 0.9640, Precision: 0.9584, Recall: 0.9776, F1: 0.9679\n",
            "Epoch: 050, Loss: 0.0685\n",
            "Train - Accuracy: 0.9699, Precision: 0.9647, Recall: 0.9816, F1: 0.9731\n",
            "Epoch: 060, Loss: 0.0473\n",
            "Train - Accuracy: 0.9776, Precision: 0.9713, Recall: 0.9888, F1: 0.9800\n",
            "Epoch: 070, Loss: 0.0331\n",
            "Train - Accuracy: 0.9818, Precision: 0.9809, Recall: 0.9863, F1: 0.9836\n",
            "Epoch: 080, Loss: 0.0580\n",
            "Train - Accuracy: 0.9801, Precision: 0.9751, Recall: 0.9894, F1: 0.9822\n",
            "Epoch: 090, Loss: 0.0365\n",
            "Train - Accuracy: 0.9830, Precision: 0.9756, Recall: 0.9943, F1: 0.9848\n",
            "Epoch: 100, Loss: 0.0266\n",
            "Train - Accuracy: 0.9879, Precision: 0.9839, Recall: 0.9945, F1: 0.9891\n",
            "Epoch: 110, Loss: 0.0213\n",
            "Train - Accuracy: 0.9897, Precision: 0.9884, Recall: 0.9931, F1: 0.9907\n",
            "Epoch: 120, Loss: 0.0207\n",
            "Train - Accuracy: 0.9889, Precision: 0.9849, Recall: 0.9953, F1: 0.9901\n",
            "Epoch: 130, Loss: 0.0240\n",
            "Train - Accuracy: 0.9891, Precision: 0.9904, Recall: 0.9900, F1: 0.9902\n",
            "Epoch: 140, Loss: 0.0208\n",
            "Train - Accuracy: 0.9903, Precision: 0.9882, Recall: 0.9943, F1: 0.9913\n",
            "Epoch: 150, Loss: 0.0185\n",
            "Train - Accuracy: 0.9898, Precision: 0.9914, Recall: 0.9902, F1: 0.9908\n",
            "Epoch: 160, Loss: 0.0178\n",
            "Train - Accuracy: 0.9906, Precision: 0.9898, Recall: 0.9933, F1: 0.9915\n",
            "Epoch: 170, Loss: 0.0179\n",
            "Train - Accuracy: 0.9905, Precision: 0.9908, Recall: 0.9920, F1: 0.9914\n",
            "Epoch: 180, Loss: 0.0178\n",
            "Train - Accuracy: 0.9902, Precision: 0.9928, Recall: 0.9894, F1: 0.9911\n",
            "Epoch: 190, Loss: 0.0178\n",
            "Train - Accuracy: 0.9906, Precision: 0.9906, Recall: 0.9925, F1: 0.9915\n",
            "Epoch: 200, Loss: 0.0176\n",
            "Train - Accuracy: 0.9906, Precision: 0.9890, Recall: 0.9941, F1: 0.9916\n",
            "Test - Accuracy: 0.9674, Precision: 0.9639, Recall: 0.9793, F1: 0.9715\n",
            "Training PreActResNet...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PreActResNet' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-98002b773af9>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResidualBlockV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvariant\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"PreActResNet\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreActResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreActResidualBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvariant\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"WideResNet\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWideResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWideResidualBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PreActResNet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data to add a channel dimension and an extra spatial dimension\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1).unsqueeze(2)  # Shape: [batch_size, channels, height, width]\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1).unsqueeze(2)  # Shape: [batch_size, channels, height, width]\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the MobileNet model\n",
        "class MobileNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNet, self).__init__()\n",
        "        self.mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "        self.mobilenet.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.mobilenet.classifier[1] = nn.Linear(self.mobilenet.last_channel, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mobilenet(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define the loss function and the optimizer\n",
        "model = MobileNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "def train_model():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = accuracy_score(labels.cpu(), predicted.cpu())\n",
        "        precision = precision_score(labels.cpu(), predicted.cpu())\n",
        "        recall = recall_score(labels.cpu(), predicted.cpu())\n",
        "        f1 = f1_score(labels.cpu(), predicted.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 21):  # Reduced number of epochs for time consideration\n",
        "    loss = train_model()\n",
        "    if epoch % 2 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "2PIy_OzGZc4v",
        "outputId": "155aa415-0994-4257-9183-78aabede22f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 0.5287\n",
            "Train - Accuracy: 0.4457, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 0.3205\n",
            "Train - Accuracy: 0.4457, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 006, Loss: 0.2193\n",
            "Train - Accuracy: 0.4457, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-51d065af875d>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Reduced number of epochs for time consideration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-51d065af875d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the simple feedforward neural network\n",
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(FeedForwardNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 2)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define the loss function and the optimizer\n",
        "input_dim = X_train.shape[1]\n",
        "model = FeedForwardNN(input_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "def train_model():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = accuracy_score(labels.cpu(), predicted.cpu())\n",
        "        precision = precision_score(labels.cpu(), predicted.cpu())\n",
        "        recall = recall_score(labels.cpu(), predicted.cpu())\n",
        "        f1 = f1_score(labels.cpu(), predicted.cpu())\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 21):  # Reduced number of epochs for time consideration\n",
        "    loss = train_model()\n",
        "    if epoch % 2 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdD4_2PZbJx4",
        "outputId": "154a9c4a-8f19-4cfe-fd0b-b9f993223c5f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 0.6919\n",
            "Train - Accuracy: 0.6124, Precision: 0.6126, Recall: 0.8182, F1: 0.7006\n",
            "Epoch: 004, Loss: 0.6612\n",
            "Train - Accuracy: 0.7101, Precision: 0.6797, Recall: 0.9019, F1: 0.7752\n",
            "Epoch: 006, Loss: 0.6322\n",
            "Train - Accuracy: 0.7612, Precision: 0.7199, Recall: 0.9317, F1: 0.8122\n",
            "Epoch: 008, Loss: 0.6029\n",
            "Train - Accuracy: 0.7886, Precision: 0.7459, Recall: 0.9380, F1: 0.8310\n",
            "Epoch: 010, Loss: 0.5722\n",
            "Train - Accuracy: 0.8117, Precision: 0.7711, Recall: 0.9392, F1: 0.8469\n",
            "Epoch: 012, Loss: 0.5397\n",
            "Train - Accuracy: 0.8353, Precision: 0.8002, Recall: 0.9366, F1: 0.8631\n",
            "Epoch: 014, Loss: 0.5052\n",
            "Train - Accuracy: 0.8541, Precision: 0.8256, Recall: 0.9341, F1: 0.8765\n",
            "Epoch: 016, Loss: 0.4696\n",
            "Train - Accuracy: 0.8710, Precision: 0.8500, Recall: 0.9317, F1: 0.8890\n",
            "Epoch: 018, Loss: 0.4335\n",
            "Train - Accuracy: 0.8814, Precision: 0.8659, Recall: 0.9300, F1: 0.8968\n",
            "Epoch: 020, Loss: 0.3980\n",
            "Train - Accuracy: 0.8892, Precision: 0.8790, Recall: 0.9278, F1: 0.9027\n",
            "Test - Accuracy: 0.8851, Precision: 0.8766, Recall: 0.9283, F1: 0.9017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Check class distribution\n",
        "print(dataset['Result'].value_counts())\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the feedforward neural network with ReLU and Leaky ReLU layers\n",
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(FeedForwardNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.leaky_relu(self.fc4(x))\n",
        "        x = self.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define the loss function and the optimizer\n",
        "input_dim = X_train.shape[1]\n",
        "model = FeedForwardNN(input_dim)\n",
        "\n",
        "# Calculate class weights to handle imbalance\n",
        "class_counts = dataset['Result'].value_counts().to_dict()\n",
        "class_weights = {cls: 1.0/count for cls, count in class_counts.items()}\n",
        "weights = torch.tensor([class_weights[cls] for cls in range(2)], dtype=torch.float32)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "def train_model():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = accuracy_score(labels.cpu(), predicted.cpu())\n",
        "        precision = precision_score(labels.cpu(), predicted.cpu(), zero_division=1)\n",
        "        recall = recall_score(labels.cpu(), predicted.cpu(), zero_division=1)\n",
        "        f1 = f1_score(labels.cpu(), predicted.cpu(), zero_division=1)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 51):  # Increased number of epochs\n",
        "    loss = train_model()\n",
        "    if epoch % 2 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV3dx5YPcFKB",
        "outputId": "7101e04b-7fa1-4405-fdaf-29e9c79915d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result\n",
            "1    6157\n",
            "0    4898\n",
            "Name: count, dtype: int64\n",
            "Epoch: 002, Loss: 0.6956\n",
            "Train - Accuracy: 0.5543, Precision: 0.5543, Recall: 1.0000, F1: 0.7132\n",
            "Epoch: 004, Loss: 0.6915\n",
            "Train - Accuracy: 0.5543, Precision: 0.5543, Recall: 1.0000, F1: 0.7132\n",
            "Epoch: 006, Loss: 0.6861\n",
            "Train - Accuracy: 0.5543, Precision: 0.5543, Recall: 1.0000, F1: 0.7132\n",
            "Epoch: 008, Loss: 0.6784\n",
            "Train - Accuracy: 0.5559, Precision: 0.5552, Recall: 1.0000, F1: 0.7140\n",
            "Epoch: 010, Loss: 0.6678\n",
            "Train - Accuracy: 0.6098, Precision: 0.5870, Recall: 0.9986, F1: 0.7394\n",
            "Epoch: 012, Loss: 0.6529\n",
            "Train - Accuracy: 0.8282, Precision: 0.7710, Recall: 0.9816, F1: 0.8637\n",
            "Epoch: 014, Loss: 0.6312\n",
            "Train - Accuracy: 0.8883, Precision: 0.8520, Recall: 0.9663, F1: 0.9056\n",
            "Epoch: 016, Loss: 0.5996\n",
            "Train - Accuracy: 0.9100, Precision: 0.8937, Recall: 0.9506, F1: 0.9213\n",
            "Epoch: 018, Loss: 0.5544\n",
            "Train - Accuracy: 0.9197, Precision: 0.9146, Recall: 0.9433, F1: 0.9287\n",
            "Epoch: 020, Loss: 0.4933\n",
            "Train - Accuracy: 0.9228, Precision: 0.9285, Recall: 0.9325, F1: 0.9305\n",
            "Epoch: 022, Loss: 0.4180\n",
            "Train - Accuracy: 0.9222, Precision: 0.9346, Recall: 0.9243, F1: 0.9294\n",
            "Epoch: 024, Loss: 0.3351\n",
            "Train - Accuracy: 0.9228, Precision: 0.9363, Recall: 0.9235, F1: 0.9299\n",
            "Epoch: 026, Loss: 0.2603\n",
            "Train - Accuracy: 0.9263, Precision: 0.9371, Recall: 0.9294, F1: 0.9332\n",
            "Epoch: 028, Loss: 0.2103\n",
            "Train - Accuracy: 0.9287, Precision: 0.9382, Recall: 0.9327, F1: 0.9354\n",
            "Epoch: 030, Loss: 0.1890\n",
            "Train - Accuracy: 0.9302, Precision: 0.9380, Recall: 0.9359, F1: 0.9370\n",
            "Epoch: 032, Loss: 0.1854\n",
            "Train - Accuracy: 0.9336, Precision: 0.9406, Recall: 0.9396, F1: 0.9401\n",
            "Epoch: 034, Loss: 0.1853\n",
            "Train - Accuracy: 0.9361, Precision: 0.9441, Recall: 0.9404, F1: 0.9423\n",
            "Epoch: 036, Loss: 0.1815\n",
            "Train - Accuracy: 0.9363, Precision: 0.9456, Recall: 0.9392, F1: 0.9424\n",
            "Epoch: 038, Loss: 0.1742\n",
            "Train - Accuracy: 0.9355, Precision: 0.9439, Recall: 0.9396, F1: 0.9417\n",
            "Epoch: 040, Loss: 0.1664\n",
            "Train - Accuracy: 0.9361, Precision: 0.9437, Recall: 0.9408, F1: 0.9423\n",
            "Epoch: 042, Loss: 0.1599\n",
            "Train - Accuracy: 0.9379, Precision: 0.9454, Recall: 0.9425, F1: 0.9439\n",
            "Epoch: 044, Loss: 0.1558\n",
            "Train - Accuracy: 0.9386, Precision: 0.9456, Recall: 0.9435, F1: 0.9446\n",
            "Epoch: 046, Loss: 0.1531\n",
            "Train - Accuracy: 0.9417, Precision: 0.9457, Recall: 0.9492, F1: 0.9475\n",
            "Epoch: 048, Loss: 0.1507\n",
            "Train - Accuracy: 0.9422, Precision: 0.9458, Recall: 0.9502, F1: 0.9480\n",
            "Epoch: 050, Loss: 0.1478\n",
            "Train - Accuracy: 0.9413, Precision: 0.9450, Recall: 0.9494, F1: 0.9472\n",
            "Test - Accuracy: 0.9322, Precision: 0.9381, Recall: 0.9426, F1: 0.9404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop the index column\n",
        "dataset = dataset.drop(columns=['index'])\n",
        "\n",
        "# Convert target labels -1 to 0\n",
        "dataset['Result'] = dataset['Result'].replace(-1, 0)\n",
        "\n",
        "# Check class distribution\n",
        "print(dataset['Result'].value_counts())\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = dataset.drop(columns=['Result'])\n",
        "y = dataset['Result']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Define the ResNet block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.BatchNorm1d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.layer(x)\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet model\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.input_layer = nn.Linear(num_features, 64)\n",
        "        self.block1 = ResidualBlock(64)\n",
        "        self.block2 = ResidualBlock(64)\n",
        "        self.block3 = ResidualBlock(64)\n",
        "        self.output_layer = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.input_layer(x))\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "# Model parameters\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = 2  # Phishing or not\n",
        "\n",
        "# Instantiate the model\n",
        "model = ResNet(num_features, num_classes)\n",
        "\n",
        "# Calculate class weights to handle imbalance\n",
        "class_counts = dataset['Result'].value_counts().to_dict()\n",
        "class_weights = {cls: 1.0/count for cls, count in class_counts.items()}\n",
        "weights = torch.tensor([class_weights[cls] for cls in range(2)], dtype=torch.float32)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the model\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train)\n",
        "    loss = criterion(output, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(data, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(data)\n",
        "        pred = output.argmax(dim=1)\n",
        "        accuracy = accuracy_score(labels.cpu(), pred.cpu())\n",
        "        precision = precision_score(labels.cpu(), pred.cpu(), zero_division=1)\n",
        "        recall = recall_score(labels.cpu(), pred.cpu(), zero_division=1)\n",
        "        f1 = f1_score(labels.cpu(), pred.cpu(), zero_division=1)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "    if epoch % 10 == 0:\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = evaluate(X_train, y_train)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Train - Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate(X_test, y_test)\n",
        "print(f'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "gI1eNTzHcQy6",
        "outputId": "ed10dc4c-49e5-42b0-a8c5-240776902941"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result\n",
            "1    6157\n",
            "0    4898\n",
            "Name: count, dtype: int64\n",
            "Epoch: 010, Loss: 0.1468\n",
            "Train - Accuracy: 0.9387, Precision: 0.9381, Recall: 0.9523, F1: 0.9451\n",
            "Epoch: 020, Loss: 0.0938\n",
            "Train - Accuracy: 0.9544, Precision: 0.9440, Recall: 0.9757, F1: 0.9596\n",
            "Epoch: 030, Loss: 0.0530\n",
            "Train - Accuracy: 0.9691, Precision: 0.9521, Recall: 0.9943, F1: 0.9728\n",
            "Epoch: 040, Loss: 0.0378\n",
            "Train - Accuracy: 0.9783, Precision: 0.9639, Recall: 0.9982, F1: 0.9808\n",
            "Epoch: 050, Loss: 0.0250\n",
            "Train - Accuracy: 0.9874, Precision: 0.9796, Recall: 0.9982, F1: 0.9888\n",
            "Epoch: 060, Loss: 0.0214\n",
            "Train - Accuracy: 0.9900, Precision: 0.9869, Recall: 0.9953, F1: 0.9911\n",
            "Epoch: 070, Loss: 0.0194\n",
            "Train - Accuracy: 0.9899, Precision: 0.9867, Recall: 0.9953, F1: 0.9910\n",
            "Epoch: 080, Loss: 0.0188\n",
            "Train - Accuracy: 0.9900, Precision: 0.9922, Recall: 0.9898, F1: 0.9910\n",
            "Epoch: 090, Loss: 0.0183\n",
            "Train - Accuracy: 0.9904, Precision: 0.9890, Recall: 0.9937, F1: 0.9914\n",
            "Epoch: 100, Loss: 0.0198\n",
            "Train - Accuracy: 0.9906, Precision: 0.9896, Recall: 0.9935, F1: 0.9916\n",
            "Epoch: 110, Loss: 0.0192\n",
            "Train - Accuracy: 0.9905, Precision: 0.9906, Recall: 0.9922, F1: 0.9914\n",
            "Epoch: 120, Loss: 0.0183\n",
            "Train - Accuracy: 0.9906, Precision: 0.9892, Recall: 0.9939, F1: 0.9916\n",
            "Epoch: 130, Loss: 0.0179\n",
            "Train - Accuracy: 0.9903, Precision: 0.9890, Recall: 0.9935, F1: 0.9912\n",
            "Epoch: 140, Loss: 0.0207\n",
            "Train - Accuracy: 0.9896, Precision: 0.9926, Recall: 0.9886, F1: 0.9906\n",
            "Epoch: 150, Loss: 0.0190\n",
            "Train - Accuracy: 0.9898, Precision: 0.9904, Recall: 0.9912, F1: 0.9908\n",
            "Epoch: 160, Loss: 0.0182\n",
            "Train - Accuracy: 0.9900, Precision: 0.9900, Recall: 0.9920, F1: 0.9910\n",
            "Epoch: 170, Loss: 0.0179\n",
            "Train - Accuracy: 0.9904, Precision: 0.9886, Recall: 0.9941, F1: 0.9914\n",
            "Epoch: 180, Loss: 0.0310\n",
            "Train - Accuracy: 0.9898, Precision: 0.9910, Recall: 0.9906, F1: 0.9908\n",
            "Epoch: 190, Loss: 0.0216\n",
            "Train - Accuracy: 0.9896, Precision: 0.9890, Recall: 0.9922, F1: 0.9906\n",
            "Epoch: 200, Loss: 0.0191\n",
            "Train - Accuracy: 0.9903, Precision: 0.9882, Recall: 0.9943, F1: 0.9913\n",
            "Test - Accuracy: 0.9643, Precision: 0.9601, Recall: 0.9777, F1: 0.9688\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 's' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a82737bc9fe9>\u001b[0m in \u001b[0;36m<cell line: 124>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
          ]
        }
      ]
    }
  ]
}